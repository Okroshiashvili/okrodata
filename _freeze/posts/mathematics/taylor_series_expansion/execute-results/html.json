{
  "hash": "17fd06a6497a1e5633ea8f276355de03",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Taylor Series Expansion with Python\"\nauthor: \"Nodar Okroshiashvili\"\ndate: \"2020-10-10\"\ndate-modified: \"2025-09-30\"\ncategories: [Mathematics, Python]\ntags: [Taylor Series Expansion, Maclaurin Series Expansion, Python, Numpy, Scipy, Sympy]\n\nabstract: |\n    Taylor and Maclaurin series with Python.\n\nimage: \"taylor.jpg\"\n---\n\n# Introduction\n\nIn this blog, I want to review famous Taylor Series Expansion and its special case  Maclaurin Series Expansion.\nAccording to [wikipedia](https://en.wikipedia.org/wiki/Taylor_series),  the aim of Taylor Series Expansion (TSE) is to represent a function as an infinite sum\nof terms that are derived from the values of that function's derivatives, which in turn are evaluated at some predefined single point.\nIn other words, by using TSE, we try to represent some given function as an infinite sum of its derivatives and these derivatives are evaluated at some single point\nwhich we can choose. Before diving into mechanics of TSE and its special case Maclaurin Series Expansion (MSE),\nit's worth to know some history behind these guys. Back in the 17th century the concept of expansion first was introduced by mathematician **James Gregory**, but in 1715 the notion of function expansion was formally introduced by **Brook Taylor**.\n\nA one-dimensional Taylor series is an expansion of a real function $\\mathbb F(x)$ about a point $x=a$ is given by:\n\n$$\n\\mathbb F(x) \\approx\n\\mathbb F(a) + \\mathbb F^{'}(a)\\cdot(x - a) + \\frac{1}{2!}\\cdot\\mathbb F^{''}(a)\\cdot(x - a)^{2} +\n\\frac{1}{3!}\\cdot\\mathbb F^{3}(a)\\cdot(x - a)^{3} + \\cdots + \\frac{1}{n!}\\cdot\\mathbb F^{n}(a)\\cdot(x - a)^{n}\n$$\n\nwhere, $n!$ denotes the factorial of $n$ and $\\mathbb F^{n}(a)$ denotes nth derivative of $\\mathbb F$\nevaluated at point $a$. Every term on the right hand side denotes the order of Taylor expansion.\nFor instance, $\\mathbb F(a)$ is zeroth-order expansion and $\\mathbb F^{'}(a)\\cdot(x - a)$ is\nthe first-order expansion. The above representation is called open-form representation of an expansion.\n\nWe can write this expansion in more compact notation in the following way:\n\n$$\n\\sum_{n = 0}^{\\infty} =\n\\frac{\\mathbb F^{n}(a)}{n!}\\cdot(x - a)^n\n$$\n\nThis is the closed-form representation of an expansion.\n\nTo see the intuition, let review some example. I'm interested what is Taylor expansion of order 3 of $cos(x)$ at $x = a$. To follow the above definition we have:\n\n$$\n\\mathbb F(x) =\ncos(x)\n$$\n\n$$\ncos(x) \\approx\ncos(a) - sin(a)\\cdot(x - a) - \\frac{1}{2}\\cdot cos(a)\\cdot (x - a)^2 + \\frac{1}{6}\\cdot sin(a)\\cdot(x - a)^3\n$$\n\nYou ask, what is $a$ and how can we choose it? $a$ is the point where we want to have $cosine$\napproximation and it can be any number from $-\\infty$ to $+\\infty$. Note that, this is not the\ncase for other functions. We are restricted to choose $a$ from **domain** of a given function.\n\nNow, let do Taylor approximation for $sin(x)$ at $x = a$\n\n$$\n\\mathbb F(x) =\nsin(x)\n$$\n\n$$\nsin(x) \\approx\nsin(a) + cos(a)\\cdot(x - a) + \\frac{1}{2}\\cdot sin(a)\\cdot (x - a)^2 - \\frac{1}{6}\\cdot cos(a)\\cdot(x - a)^3\n$$\n\nWe can go further and do Taylor series expansion for exponent $e^{x}$ at $x = a$ is\n\n$$\n\\mathbb F(x) =\ne^{x}\n$$\n\n$$\ne^{x} \\approx\ne^{a} + e^{a}\\cdot(x - a) + \\frac{1}{2}\\cdot e^{a}\\cdot (x - a)^2 + \\frac{1}{6}\\cdot e^{a}\\cdot(x - a)^3\n$$\n\nAs we have three functions approximations, let choose the value for $a$ and set it to zero and see what we will have.\n\nFor $cos(x)$ where $x = a = 0$ we have:\n\n$$\ncos(x) =\n1 - \\frac{1}{2}x^2\n$$\n\nfor $sin(x)$ at $x = a = 0$ we have:\n\n$$\nsin(x) =\nx - \\frac{1}{6}x^3\n$$\n\nFor $e^{x}$ where $x = a = 0$ we have:\n\n$$\ne^{x} =\n1 + x + \\frac{1}{2}x^2 + \\frac{1}{6}x^3\n$$\n\nThis kind of expansion is known as **Maclaurin** series expansion, in other words when\napproximation point is zero we call it Maclaurin expansion.\n\nCalculating third order approximation for these functions by hand does not seem too hard, but for higher order it's tedious. To solve this problem we can use Python, namely **Sympy** if we want to have a symbolic approximation, or **Numpy**/**Scipy** to have a numeric approximation. Not to be confused with numeric approximation and approximation point. At $a = 0$ for function $\\mathbb F(x) = e^{x}$ we had Taylor approximation\n$e^{x} = 1 + x + \\frac{1}{2}x^2 + \\frac{1}{6}x^3$. If we evaluate this expression at, say $x = 1$ we have function output. In this setup,\n\n$$\n\\mathbb F(x) = e^{x} \\approx 1 + x + \\frac{1}{2}x^2 + \\frac{1}{6}x^3\\mid_{x=1}\n$$\n\nand evaluated at $x = 1$ we have $\\mathbb F(1) = e^{1} = 2.71828182 \\approx 2.66666666$, which is close to the real output.\n\nNow let visualize these functions and their Taylor approximations at different points with a\ndifferent order of expansion. Before visualizing results it's good to have a function which\nwill do symbolic Taylor expansion for higher orders for one variable functions.\nFor multi-variable functions, it's up to you.\n\n\n## Practical Examples\n\n::: {#db81fca6 .cell execution_count=1}\n``` {.python .cell-code}\nfrom sympy import series, Symbol\nfrom sympy.functions import sin, cos, exp\nfrom sympy.plotting import plot\nfrom matplotlib import pyplot as plt\n\nplt.style.use(\"ggplot\")\n```\n:::\n\n\n::: {#60e39ed5 .cell execution_count=2}\n``` {.python .cell-code}\n# Define symbol\nx = Symbol(\"x\")\n\n\ndef taylor(function, x0, n):\n    \"\"\"\n    Do Taylor Series Expansion for a given real valued function.\n\n    Args:\n        function: function to approximate\n        x0: point where to approximate\n        n: order of approximation\n\n    Returns:\n        A list of the Taylor series expansion of the function\n    \"\"\"\n    return function.series(x, x0, n).removeO()\n\n\ndef plot_expansion(function, expansions, points, title):\n    \"\"\"\n    Plots a function and its Taylor Series Expansion\n\n    Args:\n        function: Original function\n        expansions: List of Taylor Series Expansion for that function\n        points: List of points to plot\n        title: Title of the plot\n    \"\"\"\n    p = plot(function, *expansions, points, legend=True, show=False)\n    p[0].line_color = \"blue\"\n    p[1].line_color = \"green\"\n    p[2].line_color = \"firebrick\"\n    p[3].line_color = \"black\"\n    p.title = title\n    p.show()\n```\n:::\n\n\nWhile defining \"taylor\" function, in return statement I used **\".removeO()\"** method. This method is used in series expansion to remove $\\mathit O(x^{n})$ term, which is Landau order term at $x = 0$ and not to be confused with big $\\mathit O$ notation used in computer science, which generally represents the Landau order term at $x = \\infty$.\n\nWe can do $sin(x)$, $cos(x)$, and $e(x)$ expansion by using **Sympy**.\n\n::: {#f862944e .cell execution_count=3}\n``` {.python .cell-code}\nprint(\"sin(x) =\", taylor(sin(x), 0, 4))\n\nprint(\"cos(x) =\", taylor(cos(x), 0, 4))\n\nprint(\"e(x) =\", taylor(exp(x), 0, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsin(x) = -x**3/6 + x\ncos(x) = 1 - x**2/2\ne(x) = x**3/6 + x**2/2 + x + 1\n```\n:::\n:::\n\n\nThat's not all. We can evaluate these functions at any point. For instance as we did above for $x = 1$\n\n::: {#a3be4f91 .cell execution_count=4}\n``` {.python .cell-code}\nprint(\"sin(1) =\", taylor(sin(x), 0, 4).subs(x, 1))\n\nprint(\"cos(1) =\", taylor(cos(x), 0, 4).subs(x, 1))\n\nprint(\"e(1) =\", taylor(exp(x), 0, 4).subs(x, 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsin(1) = 5/6\ncos(1) = 1/2\ne(1) = 8/3\n```\n:::\n:::\n\n\nAs we have all the necessary tools to visualize the results, let do it.\n\n\n### Sine Expansion\n\n::: {#e5488d57 .cell execution_count=5}\n``` {.python .cell-code}\n# This will plot sine and its Taylor approximations\n\nplot_expansion(\n    sin(x),\n    [taylor(sin(x), 0, 1), taylor(sin(x), 0, 3), taylor(sin(x), 0, 5)],\n    (x, -3.5, 3.5),\n    \"Taylor Series Expansion for Sine\",\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](taylor_series_expansion_files/figure-html/cell-6-output-1.png){width=662 height=469}\n:::\n:::\n\n\n### Cosine Expansion\n\n::: {#7306d3ce .cell execution_count=6}\n``` {.python .cell-code}\n# This will plot cosine and its Taylor approximations\n\nplot_expansion(\n    cos(x),\n    [taylor(cos(x), 0, 2), taylor(cos(x), 0, 4), taylor(cos(x), 0, 6)],\n    (x, -4.5, 4.5),\n    \"Taylor Series Expansion for Cosine\",\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](taylor_series_expansion_files/figure-html/cell-7-output-1.png){width=662 height=469}\n:::\n:::\n\n\n### Exponential Expansion\n\n::: {#5cf2475d .cell execution_count=7}\n``` {.python .cell-code}\n# This will plot exponent and its Taylor approximations\n\nplot_expansion(\n    exp(x),\n    [taylor(exp(x), 0, 1), taylor(exp(x), 0, 2), taylor(exp(x), 0, 3)],\n    (x, -2, 2),\n    \"Taylor Series Expansion for Exponent\",\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](taylor_series_expansion_files/figure-html/cell-8-output-1.png){width=662 height=469}\n:::\n:::\n\n\n# Conclusion\n\nTo conclude, in this post we saw how the Taylor series expansion works and coded it in Python.\nTaylor series expansion while approximating a function introduces approximation error.\nThe magnitude of error depends on the approximation order. If we increase the order of\napproximation, the error term will decrease, or we can set the tolerance level for error in advance.\nIn other words, the error term in approximation can be regarded as $N^{th}$ order **Remainder** term.\n\nFor $\\mathbb F(x)$ at $x = x_{0} = a$ the remainder term is defined as:\n\n$$\nR_{n}(x) =\n\\mathbb F(x) - P_{n}(x)\n$$\n\nWhere, $P_{n}(x)$ is the $N^{th}$ order Taylor polynomial for $\\mathbb F(x)$ at $x = x_{0} = a$. So,\n\n$$\n\\mathbb F(x) =\nP_{n}(x) + R_{n}(x)\n$$\n\nYou may wonder why you need Taylor expansion, but it's very important concept in mathematics\nand one of [mathematical beauty](https://en.wikipedia.org/wiki/Mathematical_beauty),\n[**Euler's Identity**](https://en.wikipedia.org/wiki/Euler%27s_identity) is derived from Taylor\nseries expansion of $cos(x)$, $sin(x)$, and $e(x)$. The derivation of Euler's Identity deserves separate post,\nbut if you want to see the derivation, you can take a look at [Khan Academy](https://www.khanacademy.org/math/ap-calculus-bc/bc-series-new/bc-10-14/v/euler-s-formula-and-euler-s-identity).\nMoreover, some training algorithms for neural networks, such as **Steepest Descent**, **Newton's method**, and\n**Conjugate Gradient** uses first or second order Taylor series expansion to minimize performance index.\n\n\n#### References\n* [Commonly Used Taylor Series](http://people.math.sc.edu/girardi/m142/handouts/10sTaylorPolySeries.pdf)\n* [Wikipedia](https://en.wikipedia.org/wiki/Taylor_series)\n* [Khan Academy](https://www.khanacademy.org/math/ap-calculus-bc/bc-series-new/bc-10-11/v/maclaurin-and-taylor-series-intuition)\n\n",
    "supporting": [
      "taylor_series_expansion_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}