{"title":"Lost in Pandas - Part 1","markdown":{"yaml":{"title":"Lost in Pandas - Part 1","author":"Nodar Okroshiashvili","date":"2020-04-10","categories":["Data Science"],"tags":["Pandas","Data Analysis"],"keywords":["pandas","python","data analysis","pandas tips and tricks","advance pandas","data transformation in pandas"]},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nMany have been told and written about Pandas and its capabilities. I could not imagine data scientist or data analyst who had not heard about Pandas or had not used it at least once. We all use it. Every day, every week. It does not matter how many times. It's a great tool. I use it all the time when I want to do data analysis, either it is simple calculations or complex data transformations, and it surprises me. Pandas is so simple in its form. However, imagine, how much you can do with some simple method chaining.\n\nSaying all of these, this blog aims to share my experience and amazment with Pandas. This series is not meant for beginner users and will not be short in length. These series will be based on my experience and I will try to give a detailed explanation for every step from problem definition to solving it. That's enough for now. Let get down to business.\n\n## Problem Statement\n\nWe have data. This data comes from the HR department of the company. The data contains two columns, company name, and information about its employees. Each row of the employee information column is a list of lists. The lists inside the outer list can be duplicated. It also can have duplicate values, and inner lists have at most two values.\n\n> Disclaimer:  Any name, phone, email, and the title is a pure coincidence. Data is random and fake.\n\nHere is our data.\n\n```{python}\n\nfrom collections import defaultdict\n\nimport pandas as pd\nimport numpy as np\n\n```\n\n```{python}\n\ndata = {\n    \"company_name\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n    \"info\": [\n        [[\"Name\", \"David Jones\"], [\"Title\", \"CEO\"], [\"Phone\", \"207-685-1626\"], [\"Email\", \"djones@example.org\"]],\n        [\n            [\"Name\", \"Kate Brown\"],\n            [\"Title\", \"Senior Lawyer\"],\n            [\"Phone\", \"316-978-7791\"],\n            [\"Email\", \"Kate.Brown@example.edu\"],\n            [\"Name\", \"Darin White\"],\n            [\"Title\", \"Associate Vice President\"],\n            [\"Phone\", \"316-978-3887\"],\n            [\"Email\", \"Darin.White@example.edu\"],\n        ],\n        [\n            [\"Name\", \"Scott Lamb\"],\n            [\"Title\", \"Actuary\"],\n            [\"Phone\", \"316-978-3804\"],\n            [\"Email\", \"scott.lamb@example.edu\"],\n            [\"Name\", \"Scott Lamb\"],\n            [\"Title\", \"Senior Officer\"],\n            [\"Title\", \"Application Developer\"],\n            [\"Title\", \"Blockchain Architect\"],\n            [\"Title\", \"Director of External Affairs\"],\n            [\"Name\", \"Scott\"],\n            [\"Name\", \"Scott\"],\n            [\"Title\", \"Director of Medicine\"],\n            [\"Title\", \"Product Owner\"],\n            [\"Name\", \"Mike\"],\n            [\"Title\", \"Domain Expert\"],\n            [\"Title\", \"Growth Hacker\"],\n            [\"Title\", \"Engineering Head\"],\n            [\"Title\", \"Event Manager\"],\n            [\"Name\", \"Joe\"],\n            [\"Name\", \"Mike\"],\n            [\"Title\", \"Fundraising\"],\n            [\"Title\", \"VP of Customers\"],\n            [\"Name\", \"Mike\"],\n            [\"Title\", \"Venture Capital Analyst\"],\n            [\"Title\", \"UX Designer\"],\n            [\"Name\", \"Mike\"],\n            [\"Name\", \"Susan\"],\n            [\"Name\", \"Bryan\"],\n            [\"Name\", \"Mia\"],\n            [\"Title\", \"Songwriter\"],\n        ],\n        [\n            [\"Name\", \"Rose Smith Rose Smith\"],\n            [\"Title\", \"Vice President\"],\n            [\"Title\", \"Finance and Operations Head\"],\n            [\"Phone\", \"316-978-3810\"],\n            [\"Email\", \"rose.smith@example.edu\"],\n            [\"Name\", \"Rose Smith\"],\n            [\"Title\", \"Foundation\"],\n            [\"Name\", \"Susan\"],\n            [\"Title\", \"Foundation\"],\n            [\"Title\", \"Accountant\"],\n            [\"Title\", \"Accountant\"],\n            [\"Title\", \"Executive\"],\n            [\"Title\", \"Director\"],\n            [\"Title\", \"Executive\"],\n            [\"Name\", \"Ray\"],\n            [\"Title\", \"Strategic Planning\"],\n            [\"Title\", \"Financial Analyst\"],\n            [\"Title\", \"Foundation\"],\n            [\"Title\", \"Foundation\"],\n            [\"Name\", \"Susan\"],\n            [\"Title\", \"member of the board\"],\n            [\"Title\", \"board of directors\"],\n            [\"Title\", \"president\"],\n            [\"Title\", \"board of directors\"],\n        ],\n        [\n            [\"Name\", \"Carl Clark\"],\n            [\"Title\", \"Chief \"],\n            [\"Title\", \"Operating Officer\"],\n            [\"Title\", \"PhD\"],\n            [\"Phone\", \"413-534-2745\"],\n            [\"Email\", \"Clark_Carl@example.com\"],\n        ],\n        [\n            [\"Title\", \"Board Member\"],\n            [\"Name\", \"Taylor Garcia\"],\n            [\"Phone\", \"307-733-2164\"],\n            [\"Phone\", \"307-733-4568\"],\n            [\"Email\", \"Garcia@example.org\"],\n        ],\n    ],\n}\n\n```\n\nLet convert this dictionary into Pandas DataFrame and see what data we have.\n\n```{python}\n\ndf = pd.DataFrame(data)\n\ndf.head()\n\n```\n\nWe see that the first column seems okay, but the second one not. Here we have one big list containing smaller two-element lists.\n\n```{python}\n\ndf[\"info\"].iloc[2]\n\n```\n\nAs we figured out the data structure, let define the aim.\n\n**We need to unpack lists from the second column and flatten them in tabular format in the way to preserve the order.\nMeaning that, from the above example, ```Scott Lamb``` has to have title ```Actuary``` and not other titles are allowed.\nLong story short, we need to flatten list of list and make proper DataFrame from it.**\n\n## How I approached this problem\n\nThe first idea that came to my mind was to use Pandas DataFrame ```.explode()``` method to unpack list of lists,\nwhich returned lists containing two elements. After that, I extracted these two elements into two different columns.\n\n```{python}\n\ndf_exploded = df.explode(\"info\")\n\ndf_exploded.head()\n\n```\n\n```{python}\n\n# Add two new columns\ndf_exploded.loc[:, \"tag\"] = df_exploded[\"info\"].map(lambda x: x[0])\n\ndf_exploded.loc[:, \"result\"] = df_exploded[\"info\"].map(lambda x: x[1])\n\ndf_exploded.head()\n\n```\n\nDespite unpacking the list of lists, that is not the format I wanted. So, I need to do an extra transformation.\n\n```{python}\n\ndf_exploded_final = (\n    df_exploded.groupby([\"company_name\", \"tag\"])[\"result\"]\n    .apply(lambda x: pd.Series(x.values))\n    .unstack(1)\n    .reset_index()\n    .drop([\"level_1\"], axis=1)\n)\n\ndf_exploded_final.head()\n\n```\n\nIt seems we did a good job. However, this approach is prone to errors. Namely, it does not preserve the order\nof the list values and may assign a different email to a different person. That was not what I need.\n\nSo, I decided to use another way to solve this problem. Notably, as the data contained millions of rows,\nit seemed impossible to be too precise, but I wanted to reduce the error of non-matching cases. To achieve this, I iterated over the values of ```info``` column and converted it to dict of lists, where keys are tags (identifiers) and values are actual employee information.\n\n```{python}\n\nout = []\n\nfor x in df[\"info\"].tolist():\n    groups = defaultdict(list)\n    for g, v in x:\n        groups[g].append(v)\n    out.append(dict(groups))\n\n\ndf.loc[:, \"new_info\"] = out\n\ndf[\"new_info\"].iloc[0]\n\n```\n\nThat's a step forward. After this, I was interested in counting the values for each key in dicts for each row.\nI made small changes in the above code and applied it to the ```new_info``` column.\n\n```{python}\n\nout = []\n\nfor x in df[\"new_info\"]:\n    groups = defaultdict(int)\n    for g, v in x.items():\n        groups[g] = len(list(filter(None, v)))\n    out.append(dict(groups))\n\n\ndf.loc[:, \"new_info_stats\"] = out\n\ndf[\"new_info_stats\"].iloc[0]\n\n```\n\nAs we calculated value counts for each dict, now we need to add three helper columns to the dataset for further usage.\nThese helper columns will help to differentiate matching cases and non-matching cases.\n\n```{python}\n\ndf[\"_max\"] = df[\"new_info_stats\"].apply(lambda x: max(x.values()))\n\ndf[\"_min\"] = df[\"new_info_stats\"].apply(lambda x: min(x.values()))\n\ndf.loc[:, \"max_equal_min\"] = pd.Series(np.where((df[\"_max\"] == df[\"_min\"]), 1, 0))\n\n```\n\nThe column ```max_equal_min``` is a dummy variable and helps us to differentiate matching and non-matching cases.\nThe value 1 indicates we have a matching case and value 0 - non-matching case. According to this column,\nI split data into two parts. The first only contains matching examples, and the second will have only non-matching cases.\n\n```{python}\n\ndf_first = df[df[\"max_equal_min\"] > 0].reset_index(drop=True)\n\ndf_second = df[df[\"max_equal_min\"] == 0].reset_index(drop=True)\n\n```\n\nThe pre-processing of the first DataFrame is over and is ready to flatten. To do so, I iterate over\n```new_info``` column and transform each row into Pandas DataFrame. After this step, data will be flat.\n\n```{python}\n\nnew_data = []\n\nfor j in df_first[\"new_info\"]:\n    new_data.append(pd.DataFrame(j))\n\n\ndf_first_final_i = (\n    pd.concat(new_data, axis=0, sort=False).drop_duplicates().dropna(subset=[\"Name\"]).reset_index(drop=True)\n)\n\ndf_first_final_i.head()\n\n```\n\nWoohoo, it works! However, imagine having millions of rows how slow this approach will be.\nFor this reason, I tried another method and found it much faster. Here it is.\n\n```{python}\n\ndf_first_final_ii = (\n    df_first[\"new_info\"].apply(pd.Series).apply(lambda x: x.explode()).drop_duplicates().reset_index(drop=True)\n)\n\ndf_first_final_ii.head()\n\n```\n\nFaster and cleaner solution. But, what about the second DataFrame? It turned out that the above solution\ndid not fit the second DataFrame and gave me an error. The error was ```ValueError: cannot reindex from a duplicate axis```. Before finding the solution for this error, let take a look at the data.\n\n```{python}\n\ndf_second.head()\n\n```\n\nIn the second and third row, we have one ```Name``` and three ```Title``` and two ```Phone```,\nrespectively, for the ```new_info_stats``` column. This may be due to the data entry or extraction reason.\nNot 100% sure that this is the case, but the likelihood is very high. So, we have to handle this problem properly.\nOne solution is to concatenate strings for the values of ```Title``` and ```Phone``` keys.\n\n```{python}\n\ndef process_info(record: dict) -> dict:\n    if (\n        len(record.keys()) == 4\n        and len(record.get(\"Name\")) == 1\n        and len(record.get(\"Title\")) > 1\n        and len(record.get(\"Email\")) == 1\n        and len(record.get(\"Phone\")) == 1\n    ):\n        record[\"Title\"] = [\" \".join(record.get(\"Title\"))]\n\n    elif (\n        len(record.keys()) == 4\n        and len(record.get(\"Name\")) == 1\n        and len(record.get(\"Title\")) == 1\n        and len(record.get(\"Email\")) > 1\n        and len(record.get(\"Phone\")) == 1\n    ):\n        record[\"Email\"] = [\",\".join(record.get(\"Email\"))]\n\n    elif (\n        len(record.keys()) == 4\n        and len(record.get(\"Name\")) == 1\n        and len(record.get(\"Title\")) == 1\n        and len(record.get(\"Email\")) == 1\n        and len(record.get(\"Phone\")) > 1\n    ):\n        record[\"Phone\"] = [\",\".join(record.get(\"Phone\"))]\n\n    else:\n        pass\n    return record\n\n\ndf_second[\"new_info\"] = df_second[\"new_info\"].apply(process_info)\n\n```\n\nThis is a simple logic to check if we are correctly concatenating string. After applying this function, the second DataFrame is ready to flatten. As I mentioned above the good old method did not give me the desired result for this case and then I came up to the following:\n\n```{python}\n\ndef flatten(df, column):\n    data = []\n    for i in df[column]:\n        data.append(pd.DataFrame(dict([(k, pd.Series(v)) for k, v in i.items()])))\n\n    new_df = (\n        pd.concat(data, axis=0, sort=False)\n        .drop_duplicates()\n        .dropna(subset=[\"Name\"])\n        .drop_duplicates(subset=[\"Name\", \"Title\", \"Phone\", \"Email\"])\n        .reset_index(drop=True)\n    )\n\n    return new_df\n\n\ndf_second_final = flatten(df_second, \"new_info\")\n\ndf_second_final.head()\n\n```\n\nApplied this function to the second DataFrame flattened it, and combining first and second DataFrames will give the final result.\n\n\n# Conclusion\n\nTo sum up, that was only a tiny part of this data pre-processing process.\nHowever, it was a great journey and lots to learn. What do you think? Did you find a more elegant solution? Please share it in the comments.\n","srcMarkdownNoYaml":"\n\n# Introduction\n\nMany have been told and written about Pandas and its capabilities. I could not imagine data scientist or data analyst who had not heard about Pandas or had not used it at least once. We all use it. Every day, every week. It does not matter how many times. It's a great tool. I use it all the time when I want to do data analysis, either it is simple calculations or complex data transformations, and it surprises me. Pandas is so simple in its form. However, imagine, how much you can do with some simple method chaining.\n\nSaying all of these, this blog aims to share my experience and amazment with Pandas. This series is not meant for beginner users and will not be short in length. These series will be based on my experience and I will try to give a detailed explanation for every step from problem definition to solving it. That's enough for now. Let get down to business.\n\n## Problem Statement\n\nWe have data. This data comes from the HR department of the company. The data contains two columns, company name, and information about its employees. Each row of the employee information column is a list of lists. The lists inside the outer list can be duplicated. It also can have duplicate values, and inner lists have at most two values.\n\n> Disclaimer:  Any name, phone, email, and the title is a pure coincidence. Data is random and fake.\n\nHere is our data.\n\n```{python}\n\nfrom collections import defaultdict\n\nimport pandas as pd\nimport numpy as np\n\n```\n\n```{python}\n\ndata = {\n    \"company_name\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n    \"info\": [\n        [[\"Name\", \"David Jones\"], [\"Title\", \"CEO\"], [\"Phone\", \"207-685-1626\"], [\"Email\", \"djones@example.org\"]],\n        [\n            [\"Name\", \"Kate Brown\"],\n            [\"Title\", \"Senior Lawyer\"],\n            [\"Phone\", \"316-978-7791\"],\n            [\"Email\", \"Kate.Brown@example.edu\"],\n            [\"Name\", \"Darin White\"],\n            [\"Title\", \"Associate Vice President\"],\n            [\"Phone\", \"316-978-3887\"],\n            [\"Email\", \"Darin.White@example.edu\"],\n        ],\n        [\n            [\"Name\", \"Scott Lamb\"],\n            [\"Title\", \"Actuary\"],\n            [\"Phone\", \"316-978-3804\"],\n            [\"Email\", \"scott.lamb@example.edu\"],\n            [\"Name\", \"Scott Lamb\"],\n            [\"Title\", \"Senior Officer\"],\n            [\"Title\", \"Application Developer\"],\n            [\"Title\", \"Blockchain Architect\"],\n            [\"Title\", \"Director of External Affairs\"],\n            [\"Name\", \"Scott\"],\n            [\"Name\", \"Scott\"],\n            [\"Title\", \"Director of Medicine\"],\n            [\"Title\", \"Product Owner\"],\n            [\"Name\", \"Mike\"],\n            [\"Title\", \"Domain Expert\"],\n            [\"Title\", \"Growth Hacker\"],\n            [\"Title\", \"Engineering Head\"],\n            [\"Title\", \"Event Manager\"],\n            [\"Name\", \"Joe\"],\n            [\"Name\", \"Mike\"],\n            [\"Title\", \"Fundraising\"],\n            [\"Title\", \"VP of Customers\"],\n            [\"Name\", \"Mike\"],\n            [\"Title\", \"Venture Capital Analyst\"],\n            [\"Title\", \"UX Designer\"],\n            [\"Name\", \"Mike\"],\n            [\"Name\", \"Susan\"],\n            [\"Name\", \"Bryan\"],\n            [\"Name\", \"Mia\"],\n            [\"Title\", \"Songwriter\"],\n        ],\n        [\n            [\"Name\", \"Rose Smith Rose Smith\"],\n            [\"Title\", \"Vice President\"],\n            [\"Title\", \"Finance and Operations Head\"],\n            [\"Phone\", \"316-978-3810\"],\n            [\"Email\", \"rose.smith@example.edu\"],\n            [\"Name\", \"Rose Smith\"],\n            [\"Title\", \"Foundation\"],\n            [\"Name\", \"Susan\"],\n            [\"Title\", \"Foundation\"],\n            [\"Title\", \"Accountant\"],\n            [\"Title\", \"Accountant\"],\n            [\"Title\", \"Executive\"],\n            [\"Title\", \"Director\"],\n            [\"Title\", \"Executive\"],\n            [\"Name\", \"Ray\"],\n            [\"Title\", \"Strategic Planning\"],\n            [\"Title\", \"Financial Analyst\"],\n            [\"Title\", \"Foundation\"],\n            [\"Title\", \"Foundation\"],\n            [\"Name\", \"Susan\"],\n            [\"Title\", \"member of the board\"],\n            [\"Title\", \"board of directors\"],\n            [\"Title\", \"president\"],\n            [\"Title\", \"board of directors\"],\n        ],\n        [\n            [\"Name\", \"Carl Clark\"],\n            [\"Title\", \"Chief \"],\n            [\"Title\", \"Operating Officer\"],\n            [\"Title\", \"PhD\"],\n            [\"Phone\", \"413-534-2745\"],\n            [\"Email\", \"Clark_Carl@example.com\"],\n        ],\n        [\n            [\"Title\", \"Board Member\"],\n            [\"Name\", \"Taylor Garcia\"],\n            [\"Phone\", \"307-733-2164\"],\n            [\"Phone\", \"307-733-4568\"],\n            [\"Email\", \"Garcia@example.org\"],\n        ],\n    ],\n}\n\n```\n\nLet convert this dictionary into Pandas DataFrame and see what data we have.\n\n```{python}\n\ndf = pd.DataFrame(data)\n\ndf.head()\n\n```\n\nWe see that the first column seems okay, but the second one not. Here we have one big list containing smaller two-element lists.\n\n```{python}\n\ndf[\"info\"].iloc[2]\n\n```\n\nAs we figured out the data structure, let define the aim.\n\n**We need to unpack lists from the second column and flatten them in tabular format in the way to preserve the order.\nMeaning that, from the above example, ```Scott Lamb``` has to have title ```Actuary``` and not other titles are allowed.\nLong story short, we need to flatten list of list and make proper DataFrame from it.**\n\n## How I approached this problem\n\nThe first idea that came to my mind was to use Pandas DataFrame ```.explode()``` method to unpack list of lists,\nwhich returned lists containing two elements. After that, I extracted these two elements into two different columns.\n\n```{python}\n\ndf_exploded = df.explode(\"info\")\n\ndf_exploded.head()\n\n```\n\n```{python}\n\n# Add two new columns\ndf_exploded.loc[:, \"tag\"] = df_exploded[\"info\"].map(lambda x: x[0])\n\ndf_exploded.loc[:, \"result\"] = df_exploded[\"info\"].map(lambda x: x[1])\n\ndf_exploded.head()\n\n```\n\nDespite unpacking the list of lists, that is not the format I wanted. So, I need to do an extra transformation.\n\n```{python}\n\ndf_exploded_final = (\n    df_exploded.groupby([\"company_name\", \"tag\"])[\"result\"]\n    .apply(lambda x: pd.Series(x.values))\n    .unstack(1)\n    .reset_index()\n    .drop([\"level_1\"], axis=1)\n)\n\ndf_exploded_final.head()\n\n```\n\nIt seems we did a good job. However, this approach is prone to errors. Namely, it does not preserve the order\nof the list values and may assign a different email to a different person. That was not what I need.\n\nSo, I decided to use another way to solve this problem. Notably, as the data contained millions of rows,\nit seemed impossible to be too precise, but I wanted to reduce the error of non-matching cases. To achieve this, I iterated over the values of ```info``` column and converted it to dict of lists, where keys are tags (identifiers) and values are actual employee information.\n\n```{python}\n\nout = []\n\nfor x in df[\"info\"].tolist():\n    groups = defaultdict(list)\n    for g, v in x:\n        groups[g].append(v)\n    out.append(dict(groups))\n\n\ndf.loc[:, \"new_info\"] = out\n\ndf[\"new_info\"].iloc[0]\n\n```\n\nThat's a step forward. After this, I was interested in counting the values for each key in dicts for each row.\nI made small changes in the above code and applied it to the ```new_info``` column.\n\n```{python}\n\nout = []\n\nfor x in df[\"new_info\"]:\n    groups = defaultdict(int)\n    for g, v in x.items():\n        groups[g] = len(list(filter(None, v)))\n    out.append(dict(groups))\n\n\ndf.loc[:, \"new_info_stats\"] = out\n\ndf[\"new_info_stats\"].iloc[0]\n\n```\n\nAs we calculated value counts for each dict, now we need to add three helper columns to the dataset for further usage.\nThese helper columns will help to differentiate matching cases and non-matching cases.\n\n```{python}\n\ndf[\"_max\"] = df[\"new_info_stats\"].apply(lambda x: max(x.values()))\n\ndf[\"_min\"] = df[\"new_info_stats\"].apply(lambda x: min(x.values()))\n\ndf.loc[:, \"max_equal_min\"] = pd.Series(np.where((df[\"_max\"] == df[\"_min\"]), 1, 0))\n\n```\n\nThe column ```max_equal_min``` is a dummy variable and helps us to differentiate matching and non-matching cases.\nThe value 1 indicates we have a matching case and value 0 - non-matching case. According to this column,\nI split data into two parts. The first only contains matching examples, and the second will have only non-matching cases.\n\n```{python}\n\ndf_first = df[df[\"max_equal_min\"] > 0].reset_index(drop=True)\n\ndf_second = df[df[\"max_equal_min\"] == 0].reset_index(drop=True)\n\n```\n\nThe pre-processing of the first DataFrame is over and is ready to flatten. To do so, I iterate over\n```new_info``` column and transform each row into Pandas DataFrame. After this step, data will be flat.\n\n```{python}\n\nnew_data = []\n\nfor j in df_first[\"new_info\"]:\n    new_data.append(pd.DataFrame(j))\n\n\ndf_first_final_i = (\n    pd.concat(new_data, axis=0, sort=False).drop_duplicates().dropna(subset=[\"Name\"]).reset_index(drop=True)\n)\n\ndf_first_final_i.head()\n\n```\n\nWoohoo, it works! However, imagine having millions of rows how slow this approach will be.\nFor this reason, I tried another method and found it much faster. Here it is.\n\n```{python}\n\ndf_first_final_ii = (\n    df_first[\"new_info\"].apply(pd.Series).apply(lambda x: x.explode()).drop_duplicates().reset_index(drop=True)\n)\n\ndf_first_final_ii.head()\n\n```\n\nFaster and cleaner solution. But, what about the second DataFrame? It turned out that the above solution\ndid not fit the second DataFrame and gave me an error. The error was ```ValueError: cannot reindex from a duplicate axis```. Before finding the solution for this error, let take a look at the data.\n\n```{python}\n\ndf_second.head()\n\n```\n\nIn the second and third row, we have one ```Name``` and three ```Title``` and two ```Phone```,\nrespectively, for the ```new_info_stats``` column. This may be due to the data entry or extraction reason.\nNot 100% sure that this is the case, but the likelihood is very high. So, we have to handle this problem properly.\nOne solution is to concatenate strings for the values of ```Title``` and ```Phone``` keys.\n\n```{python}\n\ndef process_info(record: dict) -> dict:\n    if (\n        len(record.keys()) == 4\n        and len(record.get(\"Name\")) == 1\n        and len(record.get(\"Title\")) > 1\n        and len(record.get(\"Email\")) == 1\n        and len(record.get(\"Phone\")) == 1\n    ):\n        record[\"Title\"] = [\" \".join(record.get(\"Title\"))]\n\n    elif (\n        len(record.keys()) == 4\n        and len(record.get(\"Name\")) == 1\n        and len(record.get(\"Title\")) == 1\n        and len(record.get(\"Email\")) > 1\n        and len(record.get(\"Phone\")) == 1\n    ):\n        record[\"Email\"] = [\",\".join(record.get(\"Email\"))]\n\n    elif (\n        len(record.keys()) == 4\n        and len(record.get(\"Name\")) == 1\n        and len(record.get(\"Title\")) == 1\n        and len(record.get(\"Email\")) == 1\n        and len(record.get(\"Phone\")) > 1\n    ):\n        record[\"Phone\"] = [\",\".join(record.get(\"Phone\"))]\n\n    else:\n        pass\n    return record\n\n\ndf_second[\"new_info\"] = df_second[\"new_info\"].apply(process_info)\n\n```\n\nThis is a simple logic to check if we are correctly concatenating string. After applying this function, the second DataFrame is ready to flatten. As I mentioned above the good old method did not give me the desired result for this case and then I came up to the following:\n\n```{python}\n\ndef flatten(df, column):\n    data = []\n    for i in df[column]:\n        data.append(pd.DataFrame(dict([(k, pd.Series(v)) for k, v in i.items()])))\n\n    new_df = (\n        pd.concat(data, axis=0, sort=False)\n        .drop_duplicates()\n        .dropna(subset=[\"Name\"])\n        .drop_duplicates(subset=[\"Name\", \"Title\", \"Phone\", \"Email\"])\n        .reset_index(drop=True)\n    )\n\n    return new_df\n\n\ndf_second_final = flatten(df_second, \"new_info\")\n\ndf_second_final.head()\n\n```\n\nApplied this function to the second DataFrame flattened it, and combining first and second DataFrames will give the final result.\n\n\n# Conclusion\n\nTo sum up, that was only a tiny part of this data pre-processing process.\nHowever, it was a great journey and lots to learn. What do you think? Did you find a more elegant solution? Please share it in the comments.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"pandas_tips_and_tricks_1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.23","theme":["flatly"],"title-block-banner":true,"comments":{"giscus":{"repo":"Okroshiashvili/okrodata","reactions-enabled":true,"input-position":"bottom","theme":"light","language":"en","loading":"lazy"}},"title":"Lost in Pandas - Part 1","author":"Nodar Okroshiashvili","date":"2020-04-10","categories":["Data Science"],"tags":["Pandas","Data Analysis"],"keywords":["pandas","python","data analysis","pandas tips and tricks","advance pandas","data transformation in pandas"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}