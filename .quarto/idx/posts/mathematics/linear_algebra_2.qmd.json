{"title":"Basic Linear Algebra with Python","markdown":{"yaml":{"title":"Basic Linear Algebra with Python","author":"Nodar Okroshiashvili","date":"2021-03-01","categories":["Mathematics"],"tags":["Linear Algebra","Python"],"keywords":["linear algebra basics in python","vectors and matrices with python","linear algebra","machine learning","python","numpy","scipy"]},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nThis is the **second** post in the blog series about linear algebra, covering the basics.\n\n\n1. [Introduction to Linear Algebra with Python](linear_algebra_1.qmd)\n2. **Basic Linear Algebra with Python**\n3. Intermediate linear algebra\n   1. Intermediate Linear Algebra with Python - Part I\n   2. Intermediate Linear Algebra with Python - Part II\n4. Advanced linear algebra\n   1. Advance Linear Algebra with Python - Part I\n   2. Advance Linear Algebra with Python - Part II\n\n\nIn this post I will introduce you to the basics of linear algebra, starting from introduciong one and two variable equations, then moving on to vectors and operations on vectors. After that, I will move on to matrices and operations defined on matrices. I will also show you how to use Python to solve linear algebra problems.\n\n\n## One Variable Equation\n\nGenerally, equations state that two things are equal. They contain one or more variables and solving them means to find the value of those variable to make equality true. This value is known as a solution. Consider the following equation:\n\n$$\n2x + 5 = 15\n$$\n\nIn this case, our variable is $x$ and the solution is $10$.\n\n```{python}\n\nx = 5\n\n2 * x + 5 == 15\n\n```\n\n\n## Two Variable Equation\n\nEquations with two variables are known as linear equations. Consider the following equation:\n\n$$\n2y + 3 = 2x - 1\n$$\n\nThis equation includes two different variables, $x$, and $y$. These variables depend on one another. \nThe value of $x$ is determined in part by the value of $y$ and vice-versa. So we can\"t solve this equation as \nin the case of one variable equation. However, we can express $y$ in terms of $x$ and obtain a result that \ndescribes a relative relationship between the variables.\n\nFor example, let's solve this equation for $y$. First, rearrage equation in a way to have following:\n\n$$\n2y = 2x - 4\n\\Rightarrow\ny = x - 2\n$$\n\n*Note that this is not linear function, this is an [affine function](https://math.stackexchange.com/questions/275310/what-is-the-difference-between-linear-and-affine-function)*\n\nBelow we will see the solution of the above equation for various values of $y$. It's also good practice to plot the solutions.\n\n```{python}\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n```\n\n```{python}\n\n# Create a dataframe with a column x, containing values from -10 to 10\ndf = pd.DataFrame({\"x\": range(-10, 11)})\n\n# Add column y, by applying the solved equation to x\ndf[\"y\"] = df[\"x\"] - 2\n\n# Display the dataframe\ndf.head()\n\n```\n\nAbove table shows valid solutions for values of $x$ in range $(-10, 10)$. Besides numerical solution, \nlet see the graphical solution.\n\n```{python}\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df[\"x\"], df[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.show()\n\n```\n\nThe solution of the above equation lies on the blue line, for any value pairs $(x,y)~\\in~\\mathbb{R}$\n\nWhen we use a linear equation to plot a line, we can easily see where the line intersects the X and Y axes of the plot. \nThese points are known as *intercepts*. The *x-intercept* is where the line intersects the X (horizontal) axis, \nand the *y-intercept* is where the line intersects the Y (horizontal) axis.\n\nThe x-intercept is the point where the line crosses the $X$ axis, and at this point, the value for $y$ is always 0. \nSimilarly, the y-intercept is where the line crosses the $Y$ axis, at which $x$ value is 0. So to find the intercepts, \nwe need to solve the equation for $x$ when $y$ is 0 and for $y$ when $x$ is 0.\n\nFor the x-intercept, we have:\n\n$$\ny = x - 2 = 0\n\\Rightarrow\nx = 2\n$$\n\nFor y-intercept, we have:\n\n$$\ny = x - 2\n\\Rightarrow\ny = 0 - 2\n\\Rightarrow\ny = -2\n$$\n\n```{python}\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\n\nplt.plot(df[\"x\"], df[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"x-intercept\", (2, 0), color=\"red\", fontsize=12)\nplt.annotate(\"y-intercept\", (0, -2), color=\"red\", fontsize=12)\nplt.show()\n\n```\n\nIt is natural to ask, what if we move one unit along the $x$ axis, how the value for the $y$ change? \nThe answer to this question is the notion of *slope*. Slope is defined as\n\n$$\nm = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}}\n$$\n\nThis means that for any given two ordered pairs of $x$ and $y$, how a change in $x$ affect $y$.\nFor example:\n\n* (5, 3)\n* (6, 4)\n\nSo, according to our formula, slope equal to:\n\n$$\nm = \\frac{4 - 3}{6 - 5} = 1\n$$\n\n\nSo what does that actually mean? Well, if we start from any point on the blue line and move one unit to the right \n(along with the $X$ axis), we'll need to move 1 unit up (along with the $Y$ axis) to get back to the blue line.\n\n\n## The Systems of Equations\n\nTo have the system of equations means that we have two or more linear equations together and we have to solve \nthem simultaneously to make the equality true. There are three possible solutions of the linear system. \nOne solution, No solution or system is inconsistent and infinitely many solutions. Generally, \nthe linear system can have two or more variables and two or more equations. There, I will consider two variable \nand two-equation system with three solutions, in order to depict the intuition. It's up to you to delve deeper.\n\n* The system with one solution, meaning two lines intersect\n\n$$\n\\begin{cases}\n2x-y = 2 \\\\ \nx+y = -2\n\\end{cases}\n$$\n\nIf we divide these equations we'll get $x=-2$ and $y=0$. This is the solution. Now let see it graphically.\n\n```{python}\n\ndf_1 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_1[\"y\"] = 2 * df_1[\"x\"] - 2\n\ndf_2 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_2[\"y\"] = -1 * df_2[\"x\"] - 2\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df_1[\"x\"], df_1[\"y\"])\nplt.plot(df_2[\"x\"], df_2[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"2x - y = 2\", (7.5, 18), weight=\"bold\")\nplt.annotate(\"x + y = -2\", (-10, 10), weight=\"bold\")\n\n# I put coordinates(0,-3) intentionally to make annotation look clear\nplt.annotate(\"Solution (x = -2 ; y = 0)\", (0, -3))\n\nplt.show()\n\n```\n\n* The system with no solution or inconsistent system, meaning two lines are parallel\n\n$$\n\\begin{cases}\n3x+2y = 3 \\\\ \n3x+2y = -4\n\\end{cases}\n$$\n\nThe system is inconsistent. There is no solution.\n\n```{python}\n\ndf_1 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_1[\"y\"] = (-3 / 2) * df_1[\"x\"] + 3 / 2\n\ndf_2 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_2[\"y\"] = (-3 / 2) * df_2[\"x\"] - 2\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df_1[\"x\"], df_1[\"y\"])\nplt.plot(df_2[\"x\"], df_2[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"3x + 2y = 3\", (-5, 10), weight=\"bold\")\nplt.annotate(\"3x + 2y = -4\", (-10, 7.5), weight=\"bold\")\nplt.show()\n\n```\n\n* The system with infinitely many solutions, meaning two lines coincide\n\n$$\n\\begin{cases}\nx-y = -3 \\\\ \n2x-2y = -6\n\\end{cases}\n$$\n\nThe system has infinitely many solutions, as one of them is a linear combination of another. \nIn this case, the second equation is scaled by 2 version of the first equation.\n\n```{python}\n\ndf_1 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_1[\"y\"] = df_1[\"x\"] - 3\n\ndf_2 = pd.DataFrame({\"x\": range(-5, 6)})\ndf_2[\"y\"] = df_2[\"x\"] - 3\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df_1[\"x\"], df_1[\"y\"])\nplt.plot(df_2[\"x\"], df_2[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"2x - 2y = -6\", (5, 5), weight=\"bold\")\nplt.annotate(\"x - y = -3\", (-5, -5), weight=\"bold\")\nplt.show()\n\n```\n\n\n## Vectors\n\n\n### Vectors and Vector Notation\n\nIn plain English, the vector is a directed arrow. Mathematically, the vector is an object that has magnitude and direction. \nMagnitude is the length of the vector and direction is from its tail to its end. In other words, imagine vector as the line \nwhich connects two points in the Cartesian Coordinate System. A vector of length $n$ is a sequence or array of $n$ numbers, \nwhich we can write as:\n\n$$\n\\vec{X} = (x_1, x_2, x_3...x_n)\n$$\n\nor\n\n$$\n\\vec{X} = [x_1, x_2, x_3, ... x_n]\n$$\n\nHorizontally represented vector is a row vector, while vertically represented vector is a column vector. Let see how they look graphically.\n\n```{python}\n\nfig, ax = plt.subplots(figsize=(10, 8))\n# Set the axes through the origin\nfor spine in [\"left\", \"bottom\"]:\n    ax.spines[spine].set_position(\"zero\")\n\nfor spine in [\"right\", \"top\"]:\n    ax.spines[spine].set_color(\"none\")\n\nax.set(xlim=(-6, 6), ylim=(-6, 6))\nax.grid()\n\nvecs = ((2, 4), (-3, 3))  # These are vectors\n\nfor v in vecs:\n    ax.annotate(\"\", xy=v, xytext=(0, 0), arrowprops=dict(facecolor=\"blue\", shrink=0, alpha=0.7, width=0.5))\n    ax.text(1.1 * v[0], 1.1 * v[1], str(v))\n\nplt.show()\n\n```\n\n\n### Dimensions of Vector\n\nThe dimension of vector is the number of elements in it. For example, the above vector is a row vector with \ndimension $1\\times n$, but if we take it as a column vector its dimension will be $n\\times 1$.\n\n$$\n\\vec{X} = [x_1,x_2,...x_n]_{1\\times~n}\n$$\n\nand\n\n$$\n\\vec{X} =\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n\n\\end{bmatrix}_{n\\times1}\n$$\n\n```{python}\n\nX = np.array([[1, 2, 3]])\nY = np.array([[1], [2], [3]])\n\nprint(\"X is a row vector with dimension\", np.shape(X))\nprint(\"Y is a column vector with dimension\", np.shape(Y))\n\n```\n\n\n### Operations on Vectors\n\nThe most common operations on vectors are vector addition/subtraction and scalar multiplication.\n\nIf we have two vectors, $\\vec{X}$ and $\\vec{Y}$, we can add them up in the following way:\n\n$$\n\\vec{X} + \\vec{Y} =\n\\begin{bmatrix}\n    x_1 \\\\\n    x_2 \\\\\n    \\vdots \\\\\n    x_n\n\\end{bmatrix}_{n\\times1} +\n\\begin{bmatrix}\n     y_1 \\\\\n     y_2 \\\\\n    \\vdots \\\\\n     y_n\n\\end{bmatrix}_{n\\times1} =\n\\begin{bmatrix}\n    x_1 + y_1 \\\\\n    x_2 + y_2 \\\\\n    \\vdots \\\\\n    x_n + y_n\n\\end{bmatrix}_{n\\times1}\n$$\n\n```{python}\n\nX = np.array([[1], [2], [3]])\nY = np.array([[3], [4], [5]])\n\nprint(\"X + Y = \", X + Y, sep=\"\\n\")\n\n```\n\nMultiplying vector by a scalar $\\alpha$, gives\n\n$$\n\\alpha \\vec{X} = \n\\begin{bmatrix}\n\\alpha x_1 \\\\\n\\alpha x_2 \\\\\n\\vdots \\\\\n\\alpha x_n\n\\end{bmatrix}_{n\\times1}\n$$\n\nFor scalar multiplication, if we have vector $X$ and scalar $\\alpha = 5$ then alpha times $X$ is:\n\n```{python}\n\nX = np.array([[1, 2, 3]])\n\nprint(5 * X)\n\n```\n\n### Vector Length\n\nThe vector length or the magnitude is calculated by the following formula:\n\n$$\n\\|\\vec{X}\\| = \\sqrt{x_1^2 + x_2^2 + x_3^2 + ... + x_n^2} = \\sqrt{\\sum_{i=1}^n x_i^2}\n$$\n\nWe can link notion of vector length to the Euclidean distance. If our vector $\\vec{X}$ has tail at origin, \n$\\vec{0} = [0_1, 0_2, 0_3, ... , 0_n]$ and point at $\\vec{X} = [x_1,x_2,...x_n]$, then Euclidean distance between tail and point is the length of $\\vec{X}$ by the formula:\n\n$$\nd(\\vec{0},\\vec{X}) = \\sqrt{(0_1 - x_1)^2 + (0_2 - x_2)^2 + ... + (0_n - x_n)^2} = \\sqrt{\\sum_{i=1}^n (0_i - x_i)^2}\n$$\n\nFor example, we have vector $X$\n\n$$\n\\vec{X} = \n\\begin{bmatrix}\n1 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n$$\n\nthen its length is\n\n$$\n\\|\\vec{X}\\| = \\sqrt{1^2 + 2^2 + 3^2} = \\sqrt{14}\n$$\n\n```{python}\n\nX = np.array([1, 2, 3])\n\n# In numpy, there are two ways to compute vector length\n\nprint(np.sqrt(np.sum(X**2)))  # More verbose method\nprint(np.linalg.norm(X))  # More concise method\n\n```\n\n\n### Unit Vector\n\nWhat if the length of a vector equal to 1? This kind of vector is known as the unit vector and it plays a very important \nrole in different calculations and formulae. We'll see it in later posts, but here unit vector is defined as \n\n$$\n\\hat{X} = \\frac{X}{\\|X\\|}\n$$\n\nwhere $\\hat{X}$ is a unit vector, the numerator is vector $\\vec{X}$ and denominator is the norm of vector $\\vec{X}$.\n\nWe can use vector $X$ from above example. We already calculated it length which is $\\|\\vec{X}\\| = \\sqrt{14}$. \nSo, we can construct unit vector $\\hat{X}$ in the following way:\n\n$$\n\\hat{X} = \\frac{X}{\\|X\\|} =\n\\frac{1}{\\sqrt{14}}; \\frac{2}{\\sqrt{14}}; \\frac{3}{\\sqrt{14}}\n\\Rightarrow\n[0.26726124; \\ 0.53452248; \\ 0.80178373]\n$$\n\n```{python}\n\nX = np.array([1, 2, 3])\n\nn = X / np.linalg.norm(X)\n\nprint(\"Vector n =\", n)\n\n```\n\n```{python}\n# If we take length of vector n, we'll get 1\n\nprint(\"The length of vector n is:\", np.linalg.norm(n))\n\n```\n\n\n### Scalar Product of Two Vectors\n\nMultiplication of two vectors is known as dot product, scalar product, or inner product and is defined by: \n\n$$\n\\langle\\, \\vec{X},\\vec{Y}\\rangle~=~\\vec{X}\\cdot\\vec{Y}~=~x_1\\times y_1 + x_2\\times y_2 + ... + x_n\\times y_n~=~\\sum_{i=1}^n x_i\\cdot y_i\n$$\n\n*The inner product is defined only when the dimensions of two vectors coincide.*\n\nAnother formula of inner product is:\n\n$$\n\\vec{X}\\cdot\\vec{Y}~=~\\|\\vec{X}\\|\\cdot\\|\\vec{Y}\\|\\cdot\\cos{\\theta}\n$$\n\nwhere $\\cos{\\theta}$ is an angle between the vectors $\\vec{X}$ and $\\vec{Y}$.\n\n```{python}\n\n# It's more convenient to represent the vector as a Numpy ndarray, rather than Python tuple.\nX = np.array([1, 2, 3])\nY = np.array((2, 4, 6))\n\n# Numpy have two possible ways to compute vector inner product\n\nscalar_prod = np.sum(X * Y)\n\ndot_prod = np.dot(X, Y)\n\nprint(\"Scalar Product is:\", scalar_prod)\nprint(\"Dot Product is:\", dot_prod)\n\n```\n\n```{python}\n\n# Compute angle between vector X and vector Y\ncosine_theta = np.dot(X, Y) / (np.linalg.norm(X) * np.linalg.norm(Y))\n\n# Angle theta\ntheta = np.arccos(cosine_theta)\n\nprint(\"Cosine theta is:\", cosine_theta)\nprint(\"Angle theta is:\", theta)\n\n```\n\n## Matrices\n\n\n### Matrices and Matrix Notation\n\nMatrix is a rectangular array of numbers and/or expressions that are arranged into rows and columns. \nThese rows and columns can be considered as row and column vectors. So, the matrix is the rectangular array \nwhich contains either row or column vectors. Generally, capital letters are used to denote matrix and lower \ncase letters to denote each element of that matrix and I will follow this convention. A matrix arranges numbers \ninto rows and columns, like this:\n\n$$\nA =\n\\begin{bmatrix}\na_{1,1} & a_{1,2}\\\\\na_{2,1} & a_{2,2}\n\\end{bmatrix}\n$$\n\nHere, matrix $A$ has four elements, denoted by lower letter $a$, where subscripts denote row and column number. \nFor example, $a_{2,1}$ denotes element at the cross of the second row and first column.\n\n\n### Dimension of Matrices\n\nIf a matrix $A$ has $n$ rows and $m$ columns, we call $A$ $n\\times m$ matrix and it is read as **\"n by m matrix\"**. \nA typical $n\\times m$ matrix $A$ can be written as:\n\n$$\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{bmatrix}_{n \\times m}\n$$\n\nWhen $n=m$ we have square matrix. To link this matrix to the vector we can rewrite it by the following way:\n\n$$\nA =\n\\begin{bmatrix}\n[a_{11} & a_{12} & \\cdots & a_{1m}] \\\\\n[a_{21} & a_{22} & \\cdots & a_{2m}] \\\\\n[\\vdots & \\vdots &  & \\vdots] \\\\\n[a_{n1} & a_{n2} & \\cdots & a_{nm}]\n\\end{bmatrix}_{n \\times m}\n$$\n\n```{python}\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nprint(\"Matrix A is\", A, sep=\"\\n\")\n\nprint(\"Dimensions of A is:\", np.shape(A))\n\n```\n\n\n### Matrix Operations\n\nWe add two matrices element-wise. In order this addition to exist, we require that the dimensions of the two matrices coincide. If we have two matrices, $A$ and $B$, addition is defined by:\n\n$$\nA + B =\n\\begin{bmatrix}\na_{11} & \\cdots & a_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\na_{n1} & \\cdots & a_{nm} \\\\\n\\end{bmatrix} +\n\\begin{bmatrix}\nb_{11} & \\cdots & b_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\nb_{n1} & \\cdots & b_{nm} \\\\\n\\end{bmatrix} =\n\\begin{bmatrix}\na_{11} + b_{11} &  \\cdots & a_{1m} + b_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\na_{n1} + b_{n1} &  \\cdots & a_{nm} + b_{nm} \\\\\n\\end{bmatrix}\n$$\n\nMatrix subtraction is defined in the same fashion as the addition.\n\n```{python}\n\nA = np.array([[1, 5, 3], [4, 2, 8], [3, 6, 9]])\n\nB = np.array([[1, 1, 3], [1, 2, 8], [0, 5, 3]])\n\nprint(\"Matrix A is:\", A, sep=\"\\n\")\n\nprint(\"Matrix B is:\", B, sep=\"\\n\")\n\nprint(\"The sum of them is:\", A + B, sep=\"\\n\")\n\nprint(\"The difference of them is:\", A - B, sep=\"\\n\")\n\n```\n\nThe negative of a matrix, is just a matrix with the sign of each element reversed:\n\n$$\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{bmatrix}\n$$\n\n$$\n-A =\n\\begin{bmatrix}\n-a_{11} & -a_{12} & \\cdots & -a_{1m} \\\\\n-a_{21} & -a_{22} & \\cdots & -a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\n-a_{n1} & -a_{n2} & \\cdots & -a_{nm}\n\\end{bmatrix}\n$$\n\n```{python}\n\nC = np.array([[-5, -3, -1], [1, 3, 5]])\n\nprint(\"Matrix C is:\", C, sep=\"\\n\")\n\nprint(\"The negative of C is:\", -C, sep=\"\\n\")\n\n```\n\nMultiplying matrices is a little more complex than the operations we've seen so far. There are two cases to consider. \nOne is *scalar multiplication* (multiplying a matrix by a single number), and second is *matrix multiplication* \n(multiplying a matrix by another matrix).\n\nIf we have some scalar or number $\\gamma$ and matrix $A$, scalar multiplication is:\n\n$$\n\\gamma A =\n\\gamma\n\\begin{bmatrix}\na_{11} &  \\cdots & a_{1m} \\\\\n\\vdots & \\vdots  & \\vdots \\\\\na_{n1} &  \\cdots & a_{nm} \\\\\n\\end{bmatrix} = \n\\begin{bmatrix}\n\\gamma a_{11} & \\cdots & \\gamma a_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\gamma a_{n1} & \\cdots & \\gamma a_{nm} \\\\\n\\end{bmatrix}\n$$\n\n```{python}\n\nscalar = 2\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n\nprint(\"Scalar is:\", scalar)\n\nprint(\"Matrix A is:\", A, sep=\"\\n\")\n\nprint(\"Matrix multiplied by the scalar is:\", scalar * A, sep=\"\\n\")\n\n```\n\nTo multiply two matrices, we take **inner product of $i$-th row of the matrix $A$ and $j$-th columns of matrix $B$**. \nIf we have two matrices $A$ is $n \\times k$ and $B$ is $j \\times m$, then to multiply $A$ and $B$, we require $k=j$, and resulting matrix $AB$ is $n \\times m$.\n\n$$\nA \\cdot B =\n\\begin{bmatrix}\na_{11} & \\cdots & a_{1k} \\\\\n\\vdots & \\vdots & \\vdots \\\\\na_{n1} & \\cdots & a_{nk} \\\\\n\\end{bmatrix}_{n\\times k}\n\\cdot\n\\begin{bmatrix}\nb_{11} & \\cdots & b_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\nb_{j1} & \\cdots & b_{jm} \\\\\n\\end{bmatrix}_{j \\times m}\n= \\quad\n$$\n\n$$\n\\begin{bmatrix}\n(a_{11} \\times b_{11} & +~\\cdots~+ & a_{1k} \\times b_{j1}),~\\cdots~,(a_{11} \\times b_{1m} & +~\\cdots~+ & a_{1k} \\times b_{jm}) \\\\\n\\vdots & \\vdots & \\vdots \\\\\n(a_{n1} \\times b_{11} & +~\\cdots~+ & a_{nk} \\times b_{j1}),~\\cdots~,(a_{n1} \\times b_{1m} & +~\\cdots~+ & a_{nk} \\times b_{jm})\\\\\n\\end{bmatrix}_{n \\times m}\n$$\n\nIf you did not catch the idea of matrix multiplication don't worry. It takes time to get used to it. Below, I will provide a numerical example to make it more clear.\n\n> **Note** that, in matrix multiplication, $A \\cdot B$ is **not** same as $B \\cdot A$.\n\n```{python}\n\n# In Numpy matrix multiplication can be done with no effort\n\nA = np.array([[1, 2, 3], [4, 5, 6]])\n\nB = np.array([[9, 8], [7, 6], [5, 4]])\n\nprint(\"A * B is:\", np.dot(A, B), sep=\"\\n\")\n\nprint(\"B * A is:\", np.dot(B, A), sep=\"\\n\")\n\n```\n\nIt's really easy to multiply a matrix by a matrix in Numpy. Let us see how it can be done by hand.\n\nLet's look at an example:\n\n$$\n\\begin{bmatrix}\n1 & 2 & 3 \\\\ 4 & 5 & 6\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n9 & 8 \\\\ 7 & 6 \\\\ 5 & 4\n\\end{bmatrix}\n$$\n\nNote that the first matrix is $2\\times 3$, and the second matrix is $3\\times 2$. \nThe important thing here is that the first matrix has two rows, and the second matrix has two columns. \nTo perform the multiplication, we first take the dot product of the first ***row*** of the first matrix (1,2,3) \nand the first ***column*** of the second matrix (9,7,5):\n\n$$\n(1,2,3)\n\\cdot\n(9,7,5) =\n(1 \\times 9) + (2 \\times 7) + (3 \\times 5) = 38\n$$\n\nIn our resulting matrix (which will always have the same number of ***rows*** as the first matrix, \nand the same number of ***columns*** as the second matrix), we can enter this into the first row and first column element:\n\n$$\n\\begin{bmatrix}\n38 & ?\\\\? & ?\n\\end{bmatrix}\n$$\n\nNow we can take the dot product of the first row of the first matrix and the second column of the second matrix:\n\n$$\n(1,2,3) \\cdot (8,6,4) = (1 \\times 8) + (2 \\times 6) + (3 \\times 4) = 32\n$$\n\nLet's add that to our resulting matrix in the first row and second column element:\n\n$$\n\\begin{bmatrix}\n38 & 32\\\\? & ?\n\\end{bmatrix}\n$$\n\nNow we can repeat this process for the second row of the first matrix and the first column of the second matrix:\n\n$$\n(4,5,6) \\cdot (9,7,5) = (4 \\times 9) + (5 \\times 7) + (6 \\times 5) = 101\n$$\n\nWhich fills in the next element in the result:\n\n$$\n\\begin{bmatrix}\n38 & 32\\\\101 & ?\n\\end{bmatrix}\n$$\n\nFinally, we get the dot product for the second row of the first matrix and the second column of the second matrix:\n\n$$\n(4,5,6) \\cdot (8,6,4) = (4 \\times 8) + (5 \\times 6) + (6 \\times 4) = 86\n$$\n\nGiving us:\n\n$$\n\\begin{bmatrix}\n38 & 32\\\\101 & 86\n\\end{bmatrix}\n$$\n\nIf this is not enough to catch the idea, take a look this [explanation](https://www.mathsisfun.com/algebra/matrix-multiplying.html)\n\n\n### Matrix Transpose\n\nIn the above example, we saw that the matrix is the collection of vectors. We also know that vectors can be horizontal \nas well as vertical, or row and column vectors. Now, what if we change in any matrix row vectors into column vectors? \nThis operation is known as transposition. The idea of this operation is to change matrix rows into matrix columns or vice versa, and is denoted by the superscript $T$. \n\n$$\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{bmatrix}_{n \\times m}\n$$\n\nthen \n\n$$\nA^{T} =\n\\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{n1} \\\\\na_{12} & a_{22} & \\cdots & a_{n2} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{1m} & a_{2m} & \\cdots & a_{nm}\n\\end{bmatrix}_{m \\times n}\n$$\n\n```{python}\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nprint(\"Matix A is:\", A, sep=\"\\n\")\n\nprint(\"Transpose of A is:\", A.T, sep=\"\\n\")\n\n```\n\n\n### Identity Matrix\n\nThere are several different types of matrices. In this post, we will introduce only **identity matix**. \nFuture post will introduce other types of matrices. An identity matrix (usually indicated by a capital $I$) \nis the equivalent in matrix terms of the number 1. It is always square matrix, \nand it has the value **1** in the diagonal element positions I<sub>1,1</sub>, I<sub>2,2</sub>, etc; \nand 0 in all other element positions. Here's an example of a $3 \\times 3$ identity matrix:\n\n$$\nI =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}_{3 \\times 3}\n$$\n\nMultiplying any matrix by an identity matrix is the same as multiplying a number by 1; the result is the same as the original value.\n\n```{python}\n\n# We have two ways to define identity matrix in Numpy.\n# First is to define by hand, like above examples, and second is to use Numpy's buildin function\n\nI_1 = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n\nI_2 = np.identity(3)\n\nprint(I_1)\n\nprint(I_2)\n\n```\n\n```{python}\n\n# Matrix identity multiplication\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nI = np.identity(3)\n\nprint(\"A = \", A, sep=\"\\n\")\n\nprint(\"A * I = \", np.dot(A, I), sep=\"\\n\")\n\n```\n\n\n# Conclusion\n\nIn this post, I tried to cover the basics of linear algebra. I depicted some theory with examples solved by \nhand as well as with Numpy. I do hope, this blog will help you to grab the necessary knowledge in linear algebra \nbasics and further gives you the direction where to dig deeper. I did not provide here further resources not to \nconfuse the reader and give freedom to look for some other materials.\n\n\n#### References\n* [Vector](https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics))\n* [Matrix](https://en.wikipedia.org/wiki/Matrix_(mathematics))\n","srcMarkdownNoYaml":"\n\n# Introduction\n\nThis is the **second** post in the blog series about linear algebra, covering the basics.\n\n\n1. [Introduction to Linear Algebra with Python](linear_algebra_1.qmd)\n2. **Basic Linear Algebra with Python**\n3. Intermediate linear algebra\n   1. Intermediate Linear Algebra with Python - Part I\n   2. Intermediate Linear Algebra with Python - Part II\n4. Advanced linear algebra\n   1. Advance Linear Algebra with Python - Part I\n   2. Advance Linear Algebra with Python - Part II\n\n\nIn this post I will introduce you to the basics of linear algebra, starting from introduciong one and two variable equations, then moving on to vectors and operations on vectors. After that, I will move on to matrices and operations defined on matrices. I will also show you how to use Python to solve linear algebra problems.\n\n\n## One Variable Equation\n\nGenerally, equations state that two things are equal. They contain one or more variables and solving them means to find the value of those variable to make equality true. This value is known as a solution. Consider the following equation:\n\n$$\n2x + 5 = 15\n$$\n\nIn this case, our variable is $x$ and the solution is $10$.\n\n```{python}\n\nx = 5\n\n2 * x + 5 == 15\n\n```\n\n\n## Two Variable Equation\n\nEquations with two variables are known as linear equations. Consider the following equation:\n\n$$\n2y + 3 = 2x - 1\n$$\n\nThis equation includes two different variables, $x$, and $y$. These variables depend on one another. \nThe value of $x$ is determined in part by the value of $y$ and vice-versa. So we can\"t solve this equation as \nin the case of one variable equation. However, we can express $y$ in terms of $x$ and obtain a result that \ndescribes a relative relationship between the variables.\n\nFor example, let's solve this equation for $y$. First, rearrage equation in a way to have following:\n\n$$\n2y = 2x - 4\n\\Rightarrow\ny = x - 2\n$$\n\n*Note that this is not linear function, this is an [affine function](https://math.stackexchange.com/questions/275310/what-is-the-difference-between-linear-and-affine-function)*\n\nBelow we will see the solution of the above equation for various values of $y$. It's also good practice to plot the solutions.\n\n```{python}\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n```\n\n```{python}\n\n# Create a dataframe with a column x, containing values from -10 to 10\ndf = pd.DataFrame({\"x\": range(-10, 11)})\n\n# Add column y, by applying the solved equation to x\ndf[\"y\"] = df[\"x\"] - 2\n\n# Display the dataframe\ndf.head()\n\n```\n\nAbove table shows valid solutions for values of $x$ in range $(-10, 10)$. Besides numerical solution, \nlet see the graphical solution.\n\n```{python}\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df[\"x\"], df[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.show()\n\n```\n\nThe solution of the above equation lies on the blue line, for any value pairs $(x,y)~\\in~\\mathbb{R}$\n\nWhen we use a linear equation to plot a line, we can easily see where the line intersects the X and Y axes of the plot. \nThese points are known as *intercepts*. The *x-intercept* is where the line intersects the X (horizontal) axis, \nand the *y-intercept* is where the line intersects the Y (horizontal) axis.\n\nThe x-intercept is the point where the line crosses the $X$ axis, and at this point, the value for $y$ is always 0. \nSimilarly, the y-intercept is where the line crosses the $Y$ axis, at which $x$ value is 0. So to find the intercepts, \nwe need to solve the equation for $x$ when $y$ is 0 and for $y$ when $x$ is 0.\n\nFor the x-intercept, we have:\n\n$$\ny = x - 2 = 0\n\\Rightarrow\nx = 2\n$$\n\nFor y-intercept, we have:\n\n$$\ny = x - 2\n\\Rightarrow\ny = 0 - 2\n\\Rightarrow\ny = -2\n$$\n\n```{python}\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\n\nplt.plot(df[\"x\"], df[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"x-intercept\", (2, 0), color=\"red\", fontsize=12)\nplt.annotate(\"y-intercept\", (0, -2), color=\"red\", fontsize=12)\nplt.show()\n\n```\n\nIt is natural to ask, what if we move one unit along the $x$ axis, how the value for the $y$ change? \nThe answer to this question is the notion of *slope*. Slope is defined as\n\n$$\nm = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}}\n$$\n\nThis means that for any given two ordered pairs of $x$ and $y$, how a change in $x$ affect $y$.\nFor example:\n\n* (5, 3)\n* (6, 4)\n\nSo, according to our formula, slope equal to:\n\n$$\nm = \\frac{4 - 3}{6 - 5} = 1\n$$\n\n\nSo what does that actually mean? Well, if we start from any point on the blue line and move one unit to the right \n(along with the $X$ axis), we'll need to move 1 unit up (along with the $Y$ axis) to get back to the blue line.\n\n\n## The Systems of Equations\n\nTo have the system of equations means that we have two or more linear equations together and we have to solve \nthem simultaneously to make the equality true. There are three possible solutions of the linear system. \nOne solution, No solution or system is inconsistent and infinitely many solutions. Generally, \nthe linear system can have two or more variables and two or more equations. There, I will consider two variable \nand two-equation system with three solutions, in order to depict the intuition. It's up to you to delve deeper.\n\n* The system with one solution, meaning two lines intersect\n\n$$\n\\begin{cases}\n2x-y = 2 \\\\ \nx+y = -2\n\\end{cases}\n$$\n\nIf we divide these equations we'll get $x=-2$ and $y=0$. This is the solution. Now let see it graphically.\n\n```{python}\n\ndf_1 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_1[\"y\"] = 2 * df_1[\"x\"] - 2\n\ndf_2 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_2[\"y\"] = -1 * df_2[\"x\"] - 2\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df_1[\"x\"], df_1[\"y\"])\nplt.plot(df_2[\"x\"], df_2[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"2x - y = 2\", (7.5, 18), weight=\"bold\")\nplt.annotate(\"x + y = -2\", (-10, 10), weight=\"bold\")\n\n# I put coordinates(0,-3) intentionally to make annotation look clear\nplt.annotate(\"Solution (x = -2 ; y = 0)\", (0, -3))\n\nplt.show()\n\n```\n\n* The system with no solution or inconsistent system, meaning two lines are parallel\n\n$$\n\\begin{cases}\n3x+2y = 3 \\\\ \n3x+2y = -4\n\\end{cases}\n$$\n\nThe system is inconsistent. There is no solution.\n\n```{python}\n\ndf_1 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_1[\"y\"] = (-3 / 2) * df_1[\"x\"] + 3 / 2\n\ndf_2 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_2[\"y\"] = (-3 / 2) * df_2[\"x\"] - 2\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df_1[\"x\"], df_1[\"y\"])\nplt.plot(df_2[\"x\"], df_2[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"3x + 2y = 3\", (-5, 10), weight=\"bold\")\nplt.annotate(\"3x + 2y = -4\", (-10, 7.5), weight=\"bold\")\nplt.show()\n\n```\n\n* The system with infinitely many solutions, meaning two lines coincide\n\n$$\n\\begin{cases}\nx-y = -3 \\\\ \n2x-2y = -6\n\\end{cases}\n$$\n\nThe system has infinitely many solutions, as one of them is a linear combination of another. \nIn this case, the second equation is scaled by 2 version of the first equation.\n\n```{python}\n\ndf_1 = pd.DataFrame({\"x\": range(-10, 11)})\ndf_1[\"y\"] = df_1[\"x\"] - 3\n\ndf_2 = pd.DataFrame({\"x\": range(-5, 6)})\ndf_2[\"y\"] = df_2[\"x\"] - 3\n\nplt.figure(num=None, figsize=(8, 6), dpi=80, facecolor=\"w\", edgecolor=\"k\")\nplt.plot(df_1[\"x\"], df_1[\"y\"])\nplt.plot(df_2[\"x\"], df_2[\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.axhline(color=\"black\")\nplt.axvline(color=\"black\")\nplt.annotate(\"2x - 2y = -6\", (5, 5), weight=\"bold\")\nplt.annotate(\"x - y = -3\", (-5, -5), weight=\"bold\")\nplt.show()\n\n```\n\n\n## Vectors\n\n\n### Vectors and Vector Notation\n\nIn plain English, the vector is a directed arrow. Mathematically, the vector is an object that has magnitude and direction. \nMagnitude is the length of the vector and direction is from its tail to its end. In other words, imagine vector as the line \nwhich connects two points in the Cartesian Coordinate System. A vector of length $n$ is a sequence or array of $n$ numbers, \nwhich we can write as:\n\n$$\n\\vec{X} = (x_1, x_2, x_3...x_n)\n$$\n\nor\n\n$$\n\\vec{X} = [x_1, x_2, x_3, ... x_n]\n$$\n\nHorizontally represented vector is a row vector, while vertically represented vector is a column vector. Let see how they look graphically.\n\n```{python}\n\nfig, ax = plt.subplots(figsize=(10, 8))\n# Set the axes through the origin\nfor spine in [\"left\", \"bottom\"]:\n    ax.spines[spine].set_position(\"zero\")\n\nfor spine in [\"right\", \"top\"]:\n    ax.spines[spine].set_color(\"none\")\n\nax.set(xlim=(-6, 6), ylim=(-6, 6))\nax.grid()\n\nvecs = ((2, 4), (-3, 3))  # These are vectors\n\nfor v in vecs:\n    ax.annotate(\"\", xy=v, xytext=(0, 0), arrowprops=dict(facecolor=\"blue\", shrink=0, alpha=0.7, width=0.5))\n    ax.text(1.1 * v[0], 1.1 * v[1], str(v))\n\nplt.show()\n\n```\n\n\n### Dimensions of Vector\n\nThe dimension of vector is the number of elements in it. For example, the above vector is a row vector with \ndimension $1\\times n$, but if we take it as a column vector its dimension will be $n\\times 1$.\n\n$$\n\\vec{X} = [x_1,x_2,...x_n]_{1\\times~n}\n$$\n\nand\n\n$$\n\\vec{X} =\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n\n\\end{bmatrix}_{n\\times1}\n$$\n\n```{python}\n\nX = np.array([[1, 2, 3]])\nY = np.array([[1], [2], [3]])\n\nprint(\"X is a row vector with dimension\", np.shape(X))\nprint(\"Y is a column vector with dimension\", np.shape(Y))\n\n```\n\n\n### Operations on Vectors\n\nThe most common operations on vectors are vector addition/subtraction and scalar multiplication.\n\nIf we have two vectors, $\\vec{X}$ and $\\vec{Y}$, we can add them up in the following way:\n\n$$\n\\vec{X} + \\vec{Y} =\n\\begin{bmatrix}\n    x_1 \\\\\n    x_2 \\\\\n    \\vdots \\\\\n    x_n\n\\end{bmatrix}_{n\\times1} +\n\\begin{bmatrix}\n     y_1 \\\\\n     y_2 \\\\\n    \\vdots \\\\\n     y_n\n\\end{bmatrix}_{n\\times1} =\n\\begin{bmatrix}\n    x_1 + y_1 \\\\\n    x_2 + y_2 \\\\\n    \\vdots \\\\\n    x_n + y_n\n\\end{bmatrix}_{n\\times1}\n$$\n\n```{python}\n\nX = np.array([[1], [2], [3]])\nY = np.array([[3], [4], [5]])\n\nprint(\"X + Y = \", X + Y, sep=\"\\n\")\n\n```\n\nMultiplying vector by a scalar $\\alpha$, gives\n\n$$\n\\alpha \\vec{X} = \n\\begin{bmatrix}\n\\alpha x_1 \\\\\n\\alpha x_2 \\\\\n\\vdots \\\\\n\\alpha x_n\n\\end{bmatrix}_{n\\times1}\n$$\n\nFor scalar multiplication, if we have vector $X$ and scalar $\\alpha = 5$ then alpha times $X$ is:\n\n```{python}\n\nX = np.array([[1, 2, 3]])\n\nprint(5 * X)\n\n```\n\n### Vector Length\n\nThe vector length or the magnitude is calculated by the following formula:\n\n$$\n\\|\\vec{X}\\| = \\sqrt{x_1^2 + x_2^2 + x_3^2 + ... + x_n^2} = \\sqrt{\\sum_{i=1}^n x_i^2}\n$$\n\nWe can link notion of vector length to the Euclidean distance. If our vector $\\vec{X}$ has tail at origin, \n$\\vec{0} = [0_1, 0_2, 0_3, ... , 0_n]$ and point at $\\vec{X} = [x_1,x_2,...x_n]$, then Euclidean distance between tail and point is the length of $\\vec{X}$ by the formula:\n\n$$\nd(\\vec{0},\\vec{X}) = \\sqrt{(0_1 - x_1)^2 + (0_2 - x_2)^2 + ... + (0_n - x_n)^2} = \\sqrt{\\sum_{i=1}^n (0_i - x_i)^2}\n$$\n\nFor example, we have vector $X$\n\n$$\n\\vec{X} = \n\\begin{bmatrix}\n1 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n$$\n\nthen its length is\n\n$$\n\\|\\vec{X}\\| = \\sqrt{1^2 + 2^2 + 3^2} = \\sqrt{14}\n$$\n\n```{python}\n\nX = np.array([1, 2, 3])\n\n# In numpy, there are two ways to compute vector length\n\nprint(np.sqrt(np.sum(X**2)))  # More verbose method\nprint(np.linalg.norm(X))  # More concise method\n\n```\n\n\n### Unit Vector\n\nWhat if the length of a vector equal to 1? This kind of vector is known as the unit vector and it plays a very important \nrole in different calculations and formulae. We'll see it in later posts, but here unit vector is defined as \n\n$$\n\\hat{X} = \\frac{X}{\\|X\\|}\n$$\n\nwhere $\\hat{X}$ is a unit vector, the numerator is vector $\\vec{X}$ and denominator is the norm of vector $\\vec{X}$.\n\nWe can use vector $X$ from above example. We already calculated it length which is $\\|\\vec{X}\\| = \\sqrt{14}$. \nSo, we can construct unit vector $\\hat{X}$ in the following way:\n\n$$\n\\hat{X} = \\frac{X}{\\|X\\|} =\n\\frac{1}{\\sqrt{14}}; \\frac{2}{\\sqrt{14}}; \\frac{3}{\\sqrt{14}}\n\\Rightarrow\n[0.26726124; \\ 0.53452248; \\ 0.80178373]\n$$\n\n```{python}\n\nX = np.array([1, 2, 3])\n\nn = X / np.linalg.norm(X)\n\nprint(\"Vector n =\", n)\n\n```\n\n```{python}\n# If we take length of vector n, we'll get 1\n\nprint(\"The length of vector n is:\", np.linalg.norm(n))\n\n```\n\n\n### Scalar Product of Two Vectors\n\nMultiplication of two vectors is known as dot product, scalar product, or inner product and is defined by: \n\n$$\n\\langle\\, \\vec{X},\\vec{Y}\\rangle~=~\\vec{X}\\cdot\\vec{Y}~=~x_1\\times y_1 + x_2\\times y_2 + ... + x_n\\times y_n~=~\\sum_{i=1}^n x_i\\cdot y_i\n$$\n\n*The inner product is defined only when the dimensions of two vectors coincide.*\n\nAnother formula of inner product is:\n\n$$\n\\vec{X}\\cdot\\vec{Y}~=~\\|\\vec{X}\\|\\cdot\\|\\vec{Y}\\|\\cdot\\cos{\\theta}\n$$\n\nwhere $\\cos{\\theta}$ is an angle between the vectors $\\vec{X}$ and $\\vec{Y}$.\n\n```{python}\n\n# It's more convenient to represent the vector as a Numpy ndarray, rather than Python tuple.\nX = np.array([1, 2, 3])\nY = np.array((2, 4, 6))\n\n# Numpy have two possible ways to compute vector inner product\n\nscalar_prod = np.sum(X * Y)\n\ndot_prod = np.dot(X, Y)\n\nprint(\"Scalar Product is:\", scalar_prod)\nprint(\"Dot Product is:\", dot_prod)\n\n```\n\n```{python}\n\n# Compute angle between vector X and vector Y\ncosine_theta = np.dot(X, Y) / (np.linalg.norm(X) * np.linalg.norm(Y))\n\n# Angle theta\ntheta = np.arccos(cosine_theta)\n\nprint(\"Cosine theta is:\", cosine_theta)\nprint(\"Angle theta is:\", theta)\n\n```\n\n## Matrices\n\n\n### Matrices and Matrix Notation\n\nMatrix is a rectangular array of numbers and/or expressions that are arranged into rows and columns. \nThese rows and columns can be considered as row and column vectors. So, the matrix is the rectangular array \nwhich contains either row or column vectors. Generally, capital letters are used to denote matrix and lower \ncase letters to denote each element of that matrix and I will follow this convention. A matrix arranges numbers \ninto rows and columns, like this:\n\n$$\nA =\n\\begin{bmatrix}\na_{1,1} & a_{1,2}\\\\\na_{2,1} & a_{2,2}\n\\end{bmatrix}\n$$\n\nHere, matrix $A$ has four elements, denoted by lower letter $a$, where subscripts denote row and column number. \nFor example, $a_{2,1}$ denotes element at the cross of the second row and first column.\n\n\n### Dimension of Matrices\n\nIf a matrix $A$ has $n$ rows and $m$ columns, we call $A$ $n\\times m$ matrix and it is read as **\"n by m matrix\"**. \nA typical $n\\times m$ matrix $A$ can be written as:\n\n$$\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{bmatrix}_{n \\times m}\n$$\n\nWhen $n=m$ we have square matrix. To link this matrix to the vector we can rewrite it by the following way:\n\n$$\nA =\n\\begin{bmatrix}\n[a_{11} & a_{12} & \\cdots & a_{1m}] \\\\\n[a_{21} & a_{22} & \\cdots & a_{2m}] \\\\\n[\\vdots & \\vdots &  & \\vdots] \\\\\n[a_{n1} & a_{n2} & \\cdots & a_{nm}]\n\\end{bmatrix}_{n \\times m}\n$$\n\n```{python}\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nprint(\"Matrix A is\", A, sep=\"\\n\")\n\nprint(\"Dimensions of A is:\", np.shape(A))\n\n```\n\n\n### Matrix Operations\n\nWe add two matrices element-wise. In order this addition to exist, we require that the dimensions of the two matrices coincide. If we have two matrices, $A$ and $B$, addition is defined by:\n\n$$\nA + B =\n\\begin{bmatrix}\na_{11} & \\cdots & a_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\na_{n1} & \\cdots & a_{nm} \\\\\n\\end{bmatrix} +\n\\begin{bmatrix}\nb_{11} & \\cdots & b_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\nb_{n1} & \\cdots & b_{nm} \\\\\n\\end{bmatrix} =\n\\begin{bmatrix}\na_{11} + b_{11} &  \\cdots & a_{1m} + b_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\na_{n1} + b_{n1} &  \\cdots & a_{nm} + b_{nm} \\\\\n\\end{bmatrix}\n$$\n\nMatrix subtraction is defined in the same fashion as the addition.\n\n```{python}\n\nA = np.array([[1, 5, 3], [4, 2, 8], [3, 6, 9]])\n\nB = np.array([[1, 1, 3], [1, 2, 8], [0, 5, 3]])\n\nprint(\"Matrix A is:\", A, sep=\"\\n\")\n\nprint(\"Matrix B is:\", B, sep=\"\\n\")\n\nprint(\"The sum of them is:\", A + B, sep=\"\\n\")\n\nprint(\"The difference of them is:\", A - B, sep=\"\\n\")\n\n```\n\nThe negative of a matrix, is just a matrix with the sign of each element reversed:\n\n$$\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{bmatrix}\n$$\n\n$$\n-A =\n\\begin{bmatrix}\n-a_{11} & -a_{12} & \\cdots & -a_{1m} \\\\\n-a_{21} & -a_{22} & \\cdots & -a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\n-a_{n1} & -a_{n2} & \\cdots & -a_{nm}\n\\end{bmatrix}\n$$\n\n```{python}\n\nC = np.array([[-5, -3, -1], [1, 3, 5]])\n\nprint(\"Matrix C is:\", C, sep=\"\\n\")\n\nprint(\"The negative of C is:\", -C, sep=\"\\n\")\n\n```\n\nMultiplying matrices is a little more complex than the operations we've seen so far. There are two cases to consider. \nOne is *scalar multiplication* (multiplying a matrix by a single number), and second is *matrix multiplication* \n(multiplying a matrix by another matrix).\n\nIf we have some scalar or number $\\gamma$ and matrix $A$, scalar multiplication is:\n\n$$\n\\gamma A =\n\\gamma\n\\begin{bmatrix}\na_{11} &  \\cdots & a_{1m} \\\\\n\\vdots & \\vdots  & \\vdots \\\\\na_{n1} &  \\cdots & a_{nm} \\\\\n\\end{bmatrix} = \n\\begin{bmatrix}\n\\gamma a_{11} & \\cdots & \\gamma a_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\gamma a_{n1} & \\cdots & \\gamma a_{nm} \\\\\n\\end{bmatrix}\n$$\n\n```{python}\n\nscalar = 2\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n\nprint(\"Scalar is:\", scalar)\n\nprint(\"Matrix A is:\", A, sep=\"\\n\")\n\nprint(\"Matrix multiplied by the scalar is:\", scalar * A, sep=\"\\n\")\n\n```\n\nTo multiply two matrices, we take **inner product of $i$-th row of the matrix $A$ and $j$-th columns of matrix $B$**. \nIf we have two matrices $A$ is $n \\times k$ and $B$ is $j \\times m$, then to multiply $A$ and $B$, we require $k=j$, and resulting matrix $AB$ is $n \\times m$.\n\n$$\nA \\cdot B =\n\\begin{bmatrix}\na_{11} & \\cdots & a_{1k} \\\\\n\\vdots & \\vdots & \\vdots \\\\\na_{n1} & \\cdots & a_{nk} \\\\\n\\end{bmatrix}_{n\\times k}\n\\cdot\n\\begin{bmatrix}\nb_{11} & \\cdots & b_{1m} \\\\\n\\vdots & \\vdots & \\vdots \\\\\nb_{j1} & \\cdots & b_{jm} \\\\\n\\end{bmatrix}_{j \\times m}\n= \\quad\n$$\n\n$$\n\\begin{bmatrix}\n(a_{11} \\times b_{11} & +~\\cdots~+ & a_{1k} \\times b_{j1}),~\\cdots~,(a_{11} \\times b_{1m} & +~\\cdots~+ & a_{1k} \\times b_{jm}) \\\\\n\\vdots & \\vdots & \\vdots \\\\\n(a_{n1} \\times b_{11} & +~\\cdots~+ & a_{nk} \\times b_{j1}),~\\cdots~,(a_{n1} \\times b_{1m} & +~\\cdots~+ & a_{nk} \\times b_{jm})\\\\\n\\end{bmatrix}_{n \\times m}\n$$\n\nIf you did not catch the idea of matrix multiplication don't worry. It takes time to get used to it. Below, I will provide a numerical example to make it more clear.\n\n> **Note** that, in matrix multiplication, $A \\cdot B$ is **not** same as $B \\cdot A$.\n\n```{python}\n\n# In Numpy matrix multiplication can be done with no effort\n\nA = np.array([[1, 2, 3], [4, 5, 6]])\n\nB = np.array([[9, 8], [7, 6], [5, 4]])\n\nprint(\"A * B is:\", np.dot(A, B), sep=\"\\n\")\n\nprint(\"B * A is:\", np.dot(B, A), sep=\"\\n\")\n\n```\n\nIt's really easy to multiply a matrix by a matrix in Numpy. Let us see how it can be done by hand.\n\nLet's look at an example:\n\n$$\n\\begin{bmatrix}\n1 & 2 & 3 \\\\ 4 & 5 & 6\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n9 & 8 \\\\ 7 & 6 \\\\ 5 & 4\n\\end{bmatrix}\n$$\n\nNote that the first matrix is $2\\times 3$, and the second matrix is $3\\times 2$. \nThe important thing here is that the first matrix has two rows, and the second matrix has two columns. \nTo perform the multiplication, we first take the dot product of the first ***row*** of the first matrix (1,2,3) \nand the first ***column*** of the second matrix (9,7,5):\n\n$$\n(1,2,3)\n\\cdot\n(9,7,5) =\n(1 \\times 9) + (2 \\times 7) + (3 \\times 5) = 38\n$$\n\nIn our resulting matrix (which will always have the same number of ***rows*** as the first matrix, \nand the same number of ***columns*** as the second matrix), we can enter this into the first row and first column element:\n\n$$\n\\begin{bmatrix}\n38 & ?\\\\? & ?\n\\end{bmatrix}\n$$\n\nNow we can take the dot product of the first row of the first matrix and the second column of the second matrix:\n\n$$\n(1,2,3) \\cdot (8,6,4) = (1 \\times 8) + (2 \\times 6) + (3 \\times 4) = 32\n$$\n\nLet's add that to our resulting matrix in the first row and second column element:\n\n$$\n\\begin{bmatrix}\n38 & 32\\\\? & ?\n\\end{bmatrix}\n$$\n\nNow we can repeat this process for the second row of the first matrix and the first column of the second matrix:\n\n$$\n(4,5,6) \\cdot (9,7,5) = (4 \\times 9) + (5 \\times 7) + (6 \\times 5) = 101\n$$\n\nWhich fills in the next element in the result:\n\n$$\n\\begin{bmatrix}\n38 & 32\\\\101 & ?\n\\end{bmatrix}\n$$\n\nFinally, we get the dot product for the second row of the first matrix and the second column of the second matrix:\n\n$$\n(4,5,6) \\cdot (8,6,4) = (4 \\times 8) + (5 \\times 6) + (6 \\times 4) = 86\n$$\n\nGiving us:\n\n$$\n\\begin{bmatrix}\n38 & 32\\\\101 & 86\n\\end{bmatrix}\n$$\n\nIf this is not enough to catch the idea, take a look this [explanation](https://www.mathsisfun.com/algebra/matrix-multiplying.html)\n\n\n### Matrix Transpose\n\nIn the above example, we saw that the matrix is the collection of vectors. We also know that vectors can be horizontal \nas well as vertical, or row and column vectors. Now, what if we change in any matrix row vectors into column vectors? \nThis operation is known as transposition. The idea of this operation is to change matrix rows into matrix columns or vice versa, and is denoted by the superscript $T$. \n\n$$\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{bmatrix}_{n \\times m}\n$$\n\nthen \n\n$$\nA^{T} =\n\\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{n1} \\\\\na_{12} & a_{22} & \\cdots & a_{n2} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\na_{1m} & a_{2m} & \\cdots & a_{nm}\n\\end{bmatrix}_{m \\times n}\n$$\n\n```{python}\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nprint(\"Matix A is:\", A, sep=\"\\n\")\n\nprint(\"Transpose of A is:\", A.T, sep=\"\\n\")\n\n```\n\n\n### Identity Matrix\n\nThere are several different types of matrices. In this post, we will introduce only **identity matix**. \nFuture post will introduce other types of matrices. An identity matrix (usually indicated by a capital $I$) \nis the equivalent in matrix terms of the number 1. It is always square matrix, \nand it has the value **1** in the diagonal element positions I<sub>1,1</sub>, I<sub>2,2</sub>, etc; \nand 0 in all other element positions. Here's an example of a $3 \\times 3$ identity matrix:\n\n$$\nI =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}_{3 \\times 3}\n$$\n\nMultiplying any matrix by an identity matrix is the same as multiplying a number by 1; the result is the same as the original value.\n\n```{python}\n\n# We have two ways to define identity matrix in Numpy.\n# First is to define by hand, like above examples, and second is to use Numpy's buildin function\n\nI_1 = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n\nI_2 = np.identity(3)\n\nprint(I_1)\n\nprint(I_2)\n\n```\n\n```{python}\n\n# Matrix identity multiplication\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nI = np.identity(3)\n\nprint(\"A = \", A, sep=\"\\n\")\n\nprint(\"A * I = \", np.dot(A, I), sep=\"\\n\")\n\n```\n\n\n# Conclusion\n\nIn this post, I tried to cover the basics of linear algebra. I depicted some theory with examples solved by \nhand as well as with Numpy. I do hope, this blog will help you to grab the necessary knowledge in linear algebra \nbasics and further gives you the direction where to dig deeper. I did not provide here further resources not to \nconfuse the reader and give freedom to look for some other materials.\n\n\n#### References\n* [Vector](https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics))\n* [Matrix](https://en.wikipedia.org/wiki/Matrix_(mathematics))\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"linear_algebra_2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.23","theme":["flatly"],"title-block-banner":true,"comments":{"giscus":{"repo":"Okroshiashvili/okrodata","reactions-enabled":true,"input-position":"bottom","theme":"light","language":"en","loading":"lazy"}},"title":"Basic Linear Algebra with Python","author":"Nodar Okroshiashvili","date":"2021-03-01","categories":["Mathematics"],"tags":["Linear Algebra","Python"],"keywords":["linear algebra basics in python","vectors and matrices with python","linear algebra","machine learning","python","numpy","scipy"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}