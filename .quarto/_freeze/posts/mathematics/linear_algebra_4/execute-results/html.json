{
  "hash": "c0cbc08fcaa45874342b4ddc6bdb834c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Intermediate Linear Algebra with Python - Part II\"\nauthor: \"Nodar Okroshiashvili\"\ndate: \"2021-03-22\"\ncategories: [Mathematics]\ntags: [Linear Algebra, Intermediate Topics]\nkeywords: [linear algebra in python, vectors in numpy, vector operations in python and numpy, linear algebra for machine learning, python, numpy, scipy, linear algebra, machine learning]\n# description: \"This is a short introduction to linear algebra with Python. It covers the basics of linear algebra and how to use Python to solve linear algebra problems.\"\n---\n\n# Introduction\n\nThis is the **fourth** post in the blog series about linear algebra, covering the matrix and matrix operations.\n\n\n1. [Introduction to Linear Algebra with Python](linear_algebra_1.qmd)\n2. [Basic Linear Algebra with Python](linear_algebra_2.qmd)\n3. **Intermediate linear algebra**\n   1. [Intermediate Linear Algebra with Python - Part I](linear_algebra_3.qmd)\n   2. **Intermediate Linear Algebra with Python - Part II**\n4. Advanced linear algebra\n   1. Advance Linear Algebra with Python - Part I\n   2. Advance Linear Algebra with Python - Part II\n\n\nIn this post I will introduce you to the notion of matrix, different types of matrices, and how to operate on them. I will also show you how to use Python to manipulate matrices.\n\n\n## Matrix\n\n\n### Types of Matrices\n\nDuring years of linear algebra evolution, there appeared different types of matrices. Some of them were fundamentals,\nsome of them appeared lately. In this part, I will introduce some basic types of matrices and give you reference to find\nsome other useful ones. Previously, I talked about the identity matrix, which operates as number 1 in matrix multiplication\nand is denoted by capital letter $I$.\n\nA **square** matrix is a matrix with the same number of rows and columns.\n\n$$\nA =\n\\begin{bmatrix}\n    a_{11} & a_{12} & a_{13} \\\\\n    a_{21} & a_{22} & a_{23} \\\\\n    a_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n$$\n\nA **diagonal** matrix is a matrix in which the entries on principal diagonal are non-zero and all the others are zeros.\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 2 & 0 \\\\\n    0 & 0 & 3\n\\end{bmatrix}\n$$\n\nScalar multiple of the identity matrix is called **scalar** matrix that is also diagonal. This means on the main diagonal all elements are equal.\n\n$$\nA =\n\\begin{bmatrix}\n    2 & 0 & 0 \\\\\n    0 & 2 & 0 \\\\\n    0 & 0 & 2\n\\end{bmatrix}\n$$\n\nA square matrix is called **triangular** matrix if all of its elements above the main diagonal are zero \n(**lower triangular matrix**) or all of its elements below the main diagonal are zero (**upper triangular matrix**).\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    4 & 5 & 0 \\\\\n    7 & 8 & 9\n\\end{bmatrix}\n\\quad\nA =\n\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    0 & 5 & 6 \\\\\n    0 & 0 & 9\n\\end{bmatrix}\n$$\n\nThese matrices are lower and upper triangular matrices, respectively.\n\nA **null** or **zero** matrix is a matrix with all elements equal to zero.\n\n$$\nA =\n\\begin{bmatrix}\n    0 & 0 & 0 \\\\\n    0 & 0 & 0 \\\\\n    0 & 0 & 0\n\\end{bmatrix}\n$$\n\nA matrix of **ones** is where all elements equal to 1.\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 1 \\\\\n    1 & 1 & 1\n\\end{bmatrix}\n$$\n\n**Symmetric** matrix is a square matrix that is equal to its own transpose or $A = A^T$. For example,\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    2 & 4 & 5 \\\\\n    3 & 5 & 6\n\\end{bmatrix}\n$$\n\nis a symmetric matrix. Furthermore, matrix elements are symmetric with respect to main diagonal or are equal.\n\nA **skew-symmetric** matrix is a square matrix whose transpose equals its negative or $A^T = -A$. For example,\n\n$$\nA =\n\\begin{bmatrix}\n    0 & 3 & 4 \\\\\n    -3 & 0 & 7 \\\\\n    -4 & -7 & 0\n\\end{bmatrix}\n\\quad\nA^T =\n\\begin{bmatrix}\n    0 & -3 & -4 \\\\\n    3 & 0 & -7 \\\\\n    4 & 7 & 0\n\\end{bmatrix}\n\\quad\n-A =\n\\begin{bmatrix}\n    0 & -3 & -4 \\\\\n    3 & 0 & -7 \\\\\n    4 & 7 & 0\n\\end{bmatrix}\n$$\n\n**Involutory** matrix is a square matrix that is equal to its own inverse. More precisely, it is the matrix whose square is the identity matrix.\n\n$$\nA =\n\\begin{bmatrix}\n    -5 & -8 & 0 \\\\\n    3 & 5 & 0 \\\\\n    1 & 2 & -1\n\\end{bmatrix}\n$$\n\nthen\n\n$$\nA^2 =\n\\begin{bmatrix}\n    -5 & -8 & 0 \\\\\n    3 & 5 & 0 \\\\\n    1 & 2 & -1\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n    -5 & -8 & 0 \\\\\n    3 & 5 & 0 \\\\\n    1 & 2 & -1\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix}\n\\ =\nI\n$$\n\nA square matrix is called **idempotent** matrix, if multiplied by itself yields itself. Equivalently, $A \\cdot A = A$\n\n$$\nA =\n\\begin{bmatrix}\n    2 & -2 & -4 \\\\\n    -1 & 3 & 4 \\\\\n    1 & -2 & -3\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n    2 & -2 & -4 \\\\\n    -1 & 3 & 4 \\\\\n    1 & -2 & -3\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    2 & -2 & -4 \\\\\n    -1 & 3 & 4 \\\\\n    1 & -2 & -3\n\\end{bmatrix}\n$$\n\nA **nildepotent** matrix is such that $A^k = 0$  for some positive integer $k$. This means, for some positive $k$,\nmultiplying matrix $A$ by $k$ times gives zero matrix. For matrix $A$ and for $k=2$ we have:\n\n$$\nA =\n\\begin{bmatrix}\n    5 & -3 & 2 \\\\\n    15 & -9 & 6 \\\\\n    10 & -6 & 4\n\\end{bmatrix}\n$$\n\n$$\n\\quad\n$$\n\n$$\nA^2 =\n\\begin{bmatrix}\n    5 & -3 & 2 \\\\\n    15 & -9 & 6 \\\\\n    10 & -6 & 4\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n    5 & -3 & 2 \\\\\n    15 & -9 & 6 \\\\\n    10 & -6 & 4\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    0 & 0 & 0 \\\\\n    0 & 0 & 0 \\\\\n    0 & 0 & 0\n\\end{bmatrix}\n$$\n\n---\n\nSo, as I said there are much much more matrices, but I restricted here due to limited space. If you think you need more,\ndefinitely check this out [wikipedia page](https://en.wikipedia.org/wiki/List_of_matrices).\n\n::: {#cdc3059d .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n```\n:::\n\n\n::: {#43c472ac .cell execution_count=2}\n``` {.python .cell-code}\n# Diagonal Matrix\ndiagonal = np.diag([1, 2, 3])\nprint(\"Diagonal Matrix\", diagonal, sep=\"\\n\")\n\n\n# Lower Triangular Matrix\nlow_triang = np.tril([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(\"Lower Triangular Matrix\", low_triang, sep=\"\\n\")\n\n\n# Upper Triangular Matrix\nupper_triang = np.triu([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(\"Upper Triangular Matrix\", upper_triang, sep=\"\\n\")\n\n\n# Matrix of Zeros\nzeros = np.zeros((3, 3), dtype=int)\nprint(\"Matrix of Zeros\", zeros, sep=\"\\n\")\n\n\n# Matrix of Ones\nones = np.ones((3, 3), dtype=int)\nprint(\"Matrix of Ones\", ones, sep=\"\\n\")\n\n\n# Identity Matrix\nidentity = np.eye(3, dtype=int)\nprint(\"Identity Matrix\", identity, sep=\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDiagonal Matrix\n[[1 0 0]\n [0 2 0]\n [0 0 3]]\nLower Triangular Matrix\n[[1 0 0]\n [4 5 0]\n [7 8 9]]\nUpper Triangular Matrix\n[[1 2 3]\n [0 5 6]\n [0 0 9]]\nMatrix of Zeros\n[[0 0 0]\n [0 0 0]\n [0 0 0]]\nMatrix of Ones\n[[1 1 1]\n [1 1 1]\n [1 1 1]]\nIdentity Matrix\n[[1 0 0]\n [0 1 0]\n [0 0 1]]\n```\n:::\n:::\n\n\n### Trace of a Matrix\n\nThe trace of $n\\times n$ square matrix $A$ is the sum of all elements on the main diagonal.\nIt is defined only for square matrices and the formula is:\n\n$$\ntr(A)=\\sum_{i=1}^{n}a_{ii} = a_{11} + a_{22} + \\cdots + a_{nn}\n$$\n\nWhere $a_{ii}$ denotes the entry on $i$-th row and $j$-th column of matrix A.\n\nFor example, Let $A$ be a matrix,\n\n$$\nA =\n\\begin{bmatrix}\n    a_{11} & a_{12} & a_{13} \\\\\n    a_{21} & a_{22} & a_{23} \\\\\n    a_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6 \\\\\n    7 & 8 & 9\n\\end{bmatrix}\n$$\n\nThen the trace is:\n\n$$\ntr(A)=\\sum_{i=1}^{3}a_{ii} = a_{11} + a_{22} + a_{33} = 1 + 5 + 9 = 15\n$$\n\n::: {#41f78ef4 .cell execution_count=3}\n``` {.python .cell-code}\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\ntrace = np.trace(A)\nprint(\"Trace: \", trace)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrace:  15\n```\n:::\n:::\n\n\n### Determinant of a Matrix\n\nThere is not plain English definition of determinant but I'll try to explain it by examples to catch the main idea behind\nof that special number. However, we can consider determinant as a function which as an input accepts $n \\times n$ matrix\nand output real or a complex number, that is called determinant of input matrix and is denoted by $det(A)$ or $|A|$.\n\nFor any $2 \\times 2$ square matrix $A$ determinant is calculated by:\n\n$$\nA =\n\\begin{bmatrix}\n    a & b \\\\\n    c & d \\\\\n\\end{bmatrix}\n$$\n\n$$\ndet(A) = ad - bc\n$$\n\nIt seems easy to calculate the determinant of any $2 \\times 2$ matrix right? Now think about how to calculate determinant\nfor higher dimensional matrices...did you find a way? If no, let me explain it step by step. \nIf we have, say $3 \\times 3$ matrix $A$ and want to calculate determinant we need some other notions such as **minors**\nand **co-factors** of that matrix.\n\n::: {#34e8ceaa .cell execution_count=4}\n``` {.python .cell-code}\nA = np.array([[4, 2, 2], [6, 2, 4], [2, 2, 8]])\n\ndeterminant = np.linalg.det(A)\nprint(\"Determinant: \", determinant)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDeterminant:  -32.000000000000014\n```\n:::\n:::\n\n\n### Minor of a Matrix\n\nA minor of matrix $A$ is the determinant of some smaller square matrix. Precisely, the minor $M_{i,j}$ is the **determinant** of\nmatrix $A$ with row $i$ and column $j$ omitted. Minor of matrix $A$ is denoted by $M_{ij}$, where $i$ and $j$ denotes element\nof $i$-th row and $j$-th column. Let have general matrix $A$:\n\n$$\nA =\n\\begin{bmatrix}\n    a_{11} & a_{12} & a_{13} \\\\\n    a_{21} & a_{22} & a_{23} \\\\\n    a_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n$$\n\nWe can take rows or columns to find all minors. It's up to you which one you take, rows or columns. Let take the columns.\nWe take the first element of our matrix $a_{11}$ and delete row and column along it. As the first element is $a_{11}$,\nwe have to delete first row and first column. After that, we take the second element of the first column which is $a_{21}$\nand do same or delete second row and first column. After that, we take the third element of the first column $a_{31}$ and\ndelete third row and first column. We have to do these for three columns. After all of that, we have:\n\n$$\nM_{11} =\n\\begin{bmatrix}\n    \\square & \\square & \\square \\\\\n    \\square & a_{22} & a_{23} \\\\\n    \\square & a_{32} & a_{33}\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{22} & a_{23} \\\\\n    a_{32} & a_{33}\n\\end{bmatrix}\n\\ =\na_{22}a_{33} - a_{23}a_{32}\n$$\n$$\n\\quad\n$$\n$$\nM_{21} =\n\\begin{bmatrix}\n    \\square & a_{12} & a_{13} \\\\\n    \\square & \\square & \\square \\\\\n    \\square & a_{32} & a_{33}\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{12} & a_{13} \\\\\n    a_{32} & a_{33}\n\\end{bmatrix}\n\\ =\na_{12}a_{33} - a_{13}a_{32}\n$$\n$$\n\\quad\n$$\n$$\nM_{31} =\n\\begin{bmatrix}\n    \\square & a_{12} & a_{13} \\\\\n    \\square & a_{22} & a_{23} \\\\\n    \\square & \\square & \\square\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{12} & a_{13} \\\\\n    a_{22} & a_{23}\n\\end{bmatrix}\n\\ =\na_{12}a_{23} - a_{13}a_{22}\n$$\n$$\n\\quad\n$$\n$$\nM_{12} =\n\\begin{bmatrix}\n    \\square & \\square & \\square \\\\\n    a_{21} & \\square & a_{23} \\\\\n    a_{31} & \\square & a_{33}\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{21} & a_{23} \\\\\n    a_{31} & a_{33}\n\\end{bmatrix}\n\\ =\na_{21}a_{33} - a_{23}a_{31}\n$$\n$$\n\\quad\n$$\n$$\nM_{22} =\n\\begin{bmatrix}\n    a_{11} & \\square & a_{13} \\\\\n    \\square & \\square & \\square \\\\\n    a_{31} & \\square & a_{33}\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{11} & a_{13} \\\\\n    a_{31} & a_{33}\n\\end{bmatrix}\n\\ =\na_{11}a_{33} - a_{13}a_{31}\n$$\n$$\n\\quad\n$$\n$$\nM_{32} =\n\\begin{bmatrix}\n    a_{11} & \\square & a_{13} \\\\\n    a_{21} & \\square & a_{23} \\\\\n    \\square & \\square & \\square\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{11} & a_{13} \\\\\n    a_{21} & a_{13}\n\\end{bmatrix}\n\\ =\na_{11}a_{13} - a_{13}a_{21}\n$$\n$$\n\\quad\n$$\n$$\nM_{13} =\n\\begin{bmatrix}\n    \\square & \\square & \\square \\\\\n    a_{21} & a_{22} & \\square \\\\\n    a_{31} & a_{32} & \\square\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{21} & a_{22} \\\\\n    a_{31} & a_{32}\n\\end{bmatrix}\n\\ =\na_{21}a_{32} - a_{22}a_{31}\n$$\n$$\n\\quad\n$$\n$$\nM_{23} =\n\\begin{bmatrix}\n    a_{11} & a_{12} & \\square \\\\\n    \\square & \\square & \\square \\\\\n    a_{31} & a_{32} & \\square\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{11} & a_{12} \\\\\n    a_{31} & a_{32}\n\\end{bmatrix}\n\\ =\na_{11}a_{32} - a_{12}a_{31}\n$$\n$$\n\\quad\n$$\n$$\nM_{33} =\n\\begin{bmatrix}\n    a_{11} & a_{12} & \\square \\\\\n    a_{21} & a_{22} & \\square \\\\\n    \\square & \\square & \\square\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    a_{11} & a_{12} \\\\\n    a_{21} & a_{22}\n\\end{bmatrix}\n\\ =\na_{11}a_{22} - a_{12}a_{21}\n$$\n\nThese nine scalars are minors of matrix $A$. Once again, minor is not smaller matrix, it is **determinant** of a smaller matrix.\n\n\n### Cofactor of a Matrix\n\nWe left one more step to compute determinant of $3 \\times 3$ matrix $A$. This step is cofactor of matrix $A$.\nThe cofactor of matrix $A$ is the minor, multiplied by $(-1)^{i+j}$ and is denoted by $C_{ij}$\n\n$$\nC_{ij} =\n(-1)^{i+j} \\cdot M_{ij}\n$$\n\nwhere $i$ is the number of row and $j$ is the number of column of matrix $A$.\n\nIn the above case our co-factors are:\n\n$$\nC_{11} =\n(-1)^{1+1} \\cdot M_{11}\n$$\n\n$$\nC_{21} =\n(-1)^{2+1} \\cdot M_{21}\n$$\n\n$$\nC_{31} =\n(-1)^{3+1} \\cdot M_{31}\n$$\n\n$$\nC_{12} =\n(-1)^{1+2} \\cdot M_{12}\n$$\n\n$$\nC_{22} =\n(-1)^{2+2} \\cdot M_{22}\n$$\n\n$$\nC_{32} =\n(-1)^{3+2} \\cdot M_{32}\n$$\n\n$$\nC_{13} =\n(-1)^{1+3} \\cdot M_{13}\n$$\n\n$$\nC_{23} =\n(-1)^{2+3} \\cdot M_{23}\n$$\n\n$$\nC_{33} =\n(-1)^{3+3} \\cdot M_{33}\n$$\n\nSo, the sum of $i$ and $j$ in the power of $(-1)$ switch the sign of every minor.\n\n\n### Determinant of a Matrix - continuation\n\nWe are ready to compute the determinant of our $3 \\times 3$ matrix $A$. We need to expand this matrix along one of\nthe row or one of the column to compute the determinant. It's up to you which one you take, row or column. Let take the\nfirst column. Now, what does expansion means? We have to fix either $i$ if we choose a row, or $j$ if we choose column.\nAt first glance it seems confusing but an example will make sense. This expansion is called **Laplace Expansion** and is\nused to compute the determinant of any $n \\times n$ matrix.\n\n$$\ndet(A) = \\sum_{j\\prime=1}^{n}a_{ij\\prime}C_{ij\\prime}\n\\ =\n\\sum_{i\\prime=1}^{n}a_{i\\prime j}C_{i\\prime j}\n$$\n\nwhere $i\\prime$ means we fixed index $i$ or row and we change only column index. In case of $j\\prime$ we fixed index $j$ or\ncolumns and change the only row. So, when $i$ is fixed it is called row expansion and when $j$ is fixed it's called column\nexpansion. $C_{ij}$ is our co-factor.\n\nTo continue the above example, let expand our initial matrix $A$ by the first column, meaning I fix $j$ to be 1 and only\nchange row index $i$ from 1 to 3. In this particular case above formula is:\n\n$$\ndet(A) = \\sum_{j\\prime=1}^{3}a_{ij\\prime}C_{ij\\prime}\n\\ =\na_{11}C_{11} + a_{21}C_{21} + a_{31}C_{31}\n$$\n\nInstead, if I choose first row, I have to fix row index $i$ and change column index $j$ from 1 to 3 and determinant formula is:\n\n$$\ndet(A) = \\sum_{i\\prime=1}^{3}a_{i\\prime j}C_{i\\prime j}\n\\ =\na_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13}\n$$\n\nBelow, you will see numerical example.\n\n\n### Matrix Division\n\nWe can't actually divide matrix by a matrix; but when we want to divide matrices, we can take advantage of the fact\nthat division by a given number is the same as multiplication by the reciprocal of that number.\n\nFor matrix division, we use a related idea; we multiply matrix by the *inverse* of a matrix. If we have two matrices $A$ and $B$, we can do:\n\n$$\nA \\div B = A \\cdot B^{-1}\n$$\n\nHere, $B^{-1}$ is the inverse of matrix $B$. As taking inverse of a matrix requires computations and is not easy, let explain it below and then return here.\n\n\n### Inverse of a Matrix\n\nThe matrix is said to be invertible if:\n\n$$\nA \\cdot A^{-1} = I\n$$\n\nwhere $I$ is the identity matrix and $A^{-1}$ is the inverse of $A$. Generally, matrix inverse is only defined for\nsquare matrices, but there still exist ways to take the inverse of non-square matrices but this is out of the scope\nof this blog series and I will not consider.\n\nFor $2 \\times 2$ matrix $A$\n\n$$\nA =\n\\begin{bmatrix}\n    a & b \\\\\n    c & d \\\\\n\\end{bmatrix}\n$$\n\nInverse of $A$ is:\n\n$$\nA^{-1} =\n\\frac{1}{ad-bc}\n\\begin{bmatrix}\n    d & -b \\\\\n    -c & a \\\\\n\\end{bmatrix}\n$$\n\nWhat happened there?\n\n- I swapped the positions of a and d\n- I changed the signs of b and c\n- I multiplied the resulting matrix by 1 over the **determinant** of the matrix $A$\n\nFor example,\n\n$$\nA =\n\\begin{bmatrix}\n    6 & 2 \\\\\n    1 & 2 \\\\\n\\end{bmatrix}\n\\quad\nA^{-1} =\n\\frac{1}{(6 \\times 2) - (2 \\times 1)}\n\\begin{bmatrix}\n    2 & -2 \\\\\n    -1 & 6 \\\\\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    0.2 & -0.2 \\\\\n    -0.1 & 0.6 \\\\\n\\end{bmatrix}\n$$\n\nto check if this is really the inverse of $A$, multiply $A$ by its inverse in order to get an identity matrix.\n\nNow let take the inverse of $3 \\times 3$ matrix. This process is long and involves taking minors, co-factors and determinant.\nAfter that, above-mentioned operations should be understandable. It has to be mentioned that there are several ways to take\nmatrix inverse but as I started here explaining minors, co-factors and determinant I use this technique to find inverse.\n\nWe can calculate the inverse by:\n\n* step 1: **Calculate the matrix of minors**\n* step 2: **Turn the matrix of minors into the matrix of cofactors**\n* step 3: **Transpose the matrix of cofactors**\n* step 4: **Multiply transpose of cofactor by 1/determinant**\n\nLet have matrix:\n\n$$\nA =\n\\begin{bmatrix}\n    4 & 2 & 2 \\\\\n    6 & 2 & 4 \\\\\n    2 & 2 & 8\n\\end{bmatrix}\n$$\n\nStep 1: **Calculate the matrix of minors**\n\n$$\nM_{11} =\n\\begin{bmatrix}\\color{blue}4 & \\color{lightgray}2 & \\color{lightgray}2\\\\\\color{lightgray}6 & \\color{red}2 & \\color{red}4\\\\\\color{lightgray}2 & \\color{red}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(2\\times8) - (4\\times2) = 8\\;\\;\\;\\;\\begin{bmatrix}8 & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\n\\end{bmatrix}\n$$\n\n$$\nM_{12} =\n\\begin{bmatrix}\\color{lightgray}4 & \\color{blue}2 & \\color{lightgray}2\\\\\\color{red}6 & \\color{lightgray}2 & \\color{red}4\\\\\\color{red}2 & \\color{lightgray}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(6\\times8) - (4\\times2) = 40\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix}\n$$\n\n$$\nM_{13} =\n\\begin{bmatrix}\\color{lightgray}4 & \\color{lightgray}2 & \\color{blue}2\\\\\\color{red}6 & \\color{red}2 & \\color{lightgray}4\\\\\\color{red}2 & \\color{red}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(6\\times2) - (2\\times2) = 8\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix}\n$$\n\n$$\nM_{21} =\n\\begin{bmatrix}\\color{lightgray}4 & \\color{red}2 & \\color{red}2\\\\\\color{blue}6 & \\color{lightgray}2 & \\color{lightgray}4\\\\\\color{lightgray}2 & \\color{red}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(2\\times8) - (2\\times2) = 12\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix}\n$$\n\n$$\nM_{22} =\n\\begin{bmatrix}\\color{red}4 & \\color{lightgray}2 & \\color{red}2\\\\\\color{lightgray}6 & \\color{blue}2 & \\color{lightgray}4\\\\\\color{red}2 & \\color{lightgray}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(4\\times8) - (2\\times2) = 28\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix}\n$$\n\n$$\nM_{23} =\n\\begin{bmatrix}\\color{red}4 & \\color{red}2 & \\color{lightgray}2\\\\\\color{lightgray}6 & \\color{lightgray}2 & \\color{blue}4\\\\\\color{red}2 & \\color{red}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(4\\times2) - (2\\times2) = 4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix}\n$$\n\n$$\nM_{31} =\n\\begin{bmatrix}\\color{lightgray}4 & \\color{red}2 & \\color{red}2\\\\\\color{lightgray}6 & \\color{red}2 & \\color{red}4\\\\\\color{blue}2 & \\color{lightgray}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(2\\times4) - (2\\times2) = 4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\4 & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix}\n$$\n\n$$\nM_{32} =\n\\begin{bmatrix}\\color{red}4 & \\color{lightgray}2 & \\color{red}2\\\\\\color{red}6 & \\color{lightgray}2 & \\color{red}4\\\\\\color{lightgray}2 & \\color{blue}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(4\\times4) - (2\\times6) = 4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\4 & 4 & \\color{lightgray}?\\end{bmatrix}\n$$\n\n$$\nM_{33} =\n\\begin{bmatrix}\\color{red}4 & \\color{red}2 & \\color{lightgray}2\\\\\\color{red}6 & \\color{red}2 & \\color{lightgray}4\\\\\\color{lightgray}2 & \\color{lightgray}2 & \\color{blue}8\\end{bmatrix}\\;\\;\\;\\;(4\\times2) - (2\\times6) = -4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\4 & 4 & -4\\end{bmatrix}\n$$\n\nOur matrix of minors is:\n\n$$\nM =\n\\begin{bmatrix}\n    8 & 40 & 8 \\\\\n    12 & 28 & 4 \\\\\n    4 & 4 & -4\n\\end{bmatrix}\n$$\n\nNote that I used rows to find minors, in contrast to columns in the previous example.\n\nStep 2: **Turn the matrix of minors into the matrix of cofactors**\n\nTo turn minors matrix into cofactor matrix, we just need to change the sign of elements in minors matrix according to\nthe rule proposed above section.\n\nCofactor matrix is:\n\n$$\nC =\n\\begin{bmatrix}\n    8 & -40 & 8 \\\\\n    -12 & 28 & -4 \\\\\n    4 & -4 & -4\n\\end{bmatrix}\n$$\n\nStep 3: **Transpose the matrix of cofactors**\n\nWe need to take the transpose of the cofactor matrix. In other words, swap their positions over the main diagonal (the main diagonal stays the same).\n\n$$\nC^{T}=\n\\begin{bmatrix}8 & \\color{green}-\\color{green}1\\color{green}2 & \\color{orange}4\\\\\\color{green}-\\color{green}4\\color{green}0 & 28 & \\color{purple}-\\color{purple}4\\\\\\color{orange}8 & \\color{purple}-\\color{purple}4 & -4\\end{bmatrix}\n$$\n\nThis matrix is called **Adjugate** or **Adjoint**, which is simple the transpose of the cofactor matrix.\n\nStep 4: **Multiply transpose of cofactor by $\\frac{1}{determinant}$**\n\nAs we did all the necessary operations to have determinant, let compute it firstly and then multiply the adjoint matrix by $\\frac{1}{determinant}$.\n\nUsing formula:\n\n$$\ndet(A) = \\sum_{i\\prime=1}^{3}a_{i\\prime j}C_{i\\prime j}\n\\ =\na_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13}\n$$\n\nWe have:\n\n$$\ndet(A) = (4 \\times 8) + (2 \\times (-40)) + (2 \\times 8) = -32\n$$\n\nNow the inverse is:\n\n$$\nA^{-1} =\n\\frac{1}{-32}\n\\cdot\n\\begin{bmatrix}\n    8 & -40 & 8 \\\\\n    -12 & 28 & -4 \\\\\n    4 & -4 & -4\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    -0.25 & 0.375 & -0.125 \\\\\n    1.25 & 0.875 & 0.125 \\\\\n    -0.25 & 0.125 & 0.125\n\\end{bmatrix}\n$$\n\nLet's verify that the original matrix multiplied by the inverse results in an identity matrix:\n\n$$\nA \\cdot A^{-1} =\n\\begin{bmatrix}4 & 2 & 2\\\\6 & 2 & 4\\\\2 & 2 & 8\\end{bmatrix} \\cdot \\begin{bmatrix}-0.25 & 0.375 & -0.125\\\\1.25 & -0.875 & 0.125\\\\-0.25 & 0.125 & 0.125\\end{bmatrix} =\n\\begin{bmatrix}1 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & 1\\end{bmatrix} = I\n$$\n\nDo you see how challenging can be finding the inverse of $4 \\times 4$ matrix? That's why we use calculators or computer program to compute it.\n\n::: {#686b1b98 .cell execution_count=5}\n``` {.python .cell-code}\nA = np.array([[4, 2, 2], [6, 2, 4], [2, 2, 8]])\n\ninverse = np.linalg.inv(A)\nprint(\"Inverse\", inverse, sep=\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInverse\n[[-0.25   0.375 -0.125]\n [ 1.25  -0.875  0.125]\n [-0.25   0.125  0.125]]\n```\n:::\n:::\n\n\n### Matrix Division - continuation\n\nAs we already know how to compute the inverse of a matrix, the division is easy now. If we have two matrices:\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6 \\\\\n    7 & 8 & 9\n\\end{bmatrix}\n$$\n\nand \n\n$$\nB =\n\\begin{bmatrix}\n    4 & 2 & 2 \\\\\n    6 & 2 & 4 \\\\\n    2 & 2 & 8\n\\end{bmatrix}\n$$\n\nthen $A$ divided by $B$ is\n\n$$\nA \\cdot B^{-1}\n\\ =\n\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6 \\\\\n    7 & 8 & 9\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n    -0.25 & 0.375 & -0.125 \\\\\n    1.25 & 0.875 & 0.125 \\\\\n    -0.25 & 0.125 & 0.125\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    1.5 & -1 & 0.5 \\\\\n    3.75 & -2.125 & 0.875 \\\\\n    6 & -3.25 & 1.25\n\\end{bmatrix}\n\\ \\equiv\nA \\div B\n$$\n\n::: {#16681e73 .cell execution_count=6}\n``` {.python .cell-code}\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nB = np.array([[4, 2, 2], [6, 2, 4], [2, 2, 8]])\n\n# A divided by B is dot product between A and inverse of B\ninv_B = np.linalg.inv(B)\nX = np.dot(A, inv_B)\n\nprint(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[ 1.5   -1.     0.5  ]\n [ 3.75  -2.125  0.875]\n [ 6.    -3.25   1.25 ]]\n```\n:::\n:::\n\n\n### Solving System of Equations with Matrices\n\nIn the previous blog, I talked about the system of linear equations and we solved this system graphically and algebraically.\nOne of the great things about matrices, is that they can help us solve systems of equations. For example, consider the following system of equations:\n\n$$\n\\begin{cases}\n2x + 4y = 18 \\\\\n6x + 2y = 34\n\\end{cases}\n$$\n\nWe can write this in matrix form, like this:\n\n$$\n\\begin{bmatrix}\n    2 & 4 \\\\\n    6 & 2\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n    x \\\\\n    y\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    18 \\\\\n    34\n\\end{bmatrix}\n$$\n\nIf we calculate the dot product between the matrix and vector on the left side, we can see clearly that this represents the original equations.\n\nNow let rename our matrices:\n\n$$\nA =\n\\begin{bmatrix}\n    2 & 4 \\\\\n    6 & 2\n\\end{bmatrix}\n\\quad\nX =\n\\begin{bmatrix}\n    x \\\\\n    y\n\\end{bmatrix}\n\\quad\nB = \n\\begin{bmatrix}\n    18 \\\\\n    34\n\\end{bmatrix}\n$$\n\nThis can be represented as $AX = B$ and we know that to find $X$ we have to solve this: $B \\div A$. Since we cannot\ndivide matrices in this way, we have to use the previous technique. Find the inverse of $A$ and multiply by $B$.\n\nThe inverse of $A$:\n\n$$\nA^{-1} =\n\\begin{bmatrix}\n    -0.1 & 0.2 \\\\\n    0.3 & -0.1\n\\end{bmatrix}\n$$\n\n$$\nX =\n\\begin{bmatrix}\n    -0.1 & 0.2 \\\\\n    0.3 & -0.1\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n    18 \\\\\n    34\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    5 \\\\\n    2\n\\end{bmatrix}\n$$\n\nNow, instead of $x$ and $y$ in the original equation put $5$ and $2$ and this will make equality true.\n\n$$\n10 + 8 = 18\n$$\n$$\n30 + 4 = 34\n$$\n\n::: {#834d72ea .cell execution_count=7}\n``` {.python .cell-code}\nA = np.array([[2, 4], [6, 2]])\n\nB = np.array([[18], [34]])\n\nA_inverse = np.linalg.inv(A)\n\nprint(\"The inverse of A is\", A_inverse, sep=\"\\n\")\n\nX = np.dot(A_inverse, B)\n\nprint(\"X =\", X, sep=\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe inverse of A is\n[[-0.1  0.2]\n [ 0.3 -0.1]]\nX =\n[[5.]\n [2.]]\n```\n:::\n:::\n\n\n### Elementary Row Operations\n\nElementary row operations (ERO) play an important role in many matrix algebra applications,\nsuch as finding the inverse of a matrix and solving simultaneous linear equations.\nThese topics are covered in advance part of the series. An ERO transforms a given matrix $A$ into a\nnew matrix $A^{'}$ via one of the following operations:\n\n1. Interchange two rows (or columns)\n2. Multiply each element in a row (or column) by a non-zero number\n3. Multiply a row (or column) by a non-zero number and add the result to another row (or column)\n\nTo catch the idea behind this operations let do the example. We have a matrix $A$ such that\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 2 & 3 & 4 \\\\\n    1 & 3 & 5 & 6 \\\\\n    0 & 1 & 2 & 3\n\\end{bmatrix}\n$$\n\nType 1 ERO that interchange rows 1 and 3 of $A$ would yield\n\n$$\nA^{'} =\n\\begin{bmatrix}\n    0 & 1 & 2 & 3 \\\\\n    1 & 3 & 5 & 6 \\\\\n    1 & 2 & 3 & 4\n\\end{bmatrix}\n$$\n\nType 2 ERO that multiplies row 2 of $A$ by 3 would yield\n\n$$\nA^{'} =\n\\begin{bmatrix}\n    1 & 2 & 3 & 4 \\\\\n    3 & 9 & 15 & 18 \\\\\n    0 & 1 & 2 & 3\n\\end{bmatrix}\n$$\n\nType 3 ERO that multiplies row 2 of $A$ by 4 and replace row 3 of $A$ by $4 \\times (\\text{row 2 of A}) + \\text{row 3 of A}$,\n\nwould yield row 3 of $A^{'}$ to be\n\n$4 \\times [1 \\ 3 \\ 5 \\ 6] + [0 \\ 1 \\ 2 \\ 3] = [4 \\ 13 \\ 22 \\ 27]$\n\nand\n\n$$\nA^{'} =\n\\begin{bmatrix}\n    1 & 2 & 3 & 4 \\\\\n    1 & 3 & 5 & 6 \\\\\n    4 & 13 & 22 & 27\n\\end{bmatrix}\n$$\n\nExcept this, to perform an elementary row operation on the matrix $A$, first we can perform the operation on the\ncorresponding **identity matrix** to obtain an elementary matrix, then multiply $A$ on the left by this elementary matrix.\nMore precisely this means that we take one ERO, whichever we want and perform this operation on corresponding identity\nmatrix of $A$. If $A$ has $m \\times n$ dimension we have identity matrix $I_{m \\times n}$. After that, we multiply $A$\nby this identity matrix. If we denote the elementary matrix by $E$ then, we multiply $A$ by $E$ in the following way:\n\n$$\n\\begin{equation}E_{1} \\cdot A \\end{equation}\n$$\n\nwhere $E_{1}$ is ERO one performed on identity matrix.\n\n\n### Rank of a Matrix\n\nThe maximum number of linearly independent rows in a matrix $A$ is called the **row rank** of $A$ and the maximum\nnumber of linearly independent columns in $A$ is called the **column rank** of $A$. If $A$ is $n \\times m$ matrix,\nthat is if matrix $A$ has $m$ rows and $n$ columns then the following inequality holds:\n\n$$\n\\text{row rank of} \\ A \\leq m \\\\\n\\text{column rank of} \\ A \\leq n\n$$\n\nFurthermore, for any matrix $A$\n\n$$\n\\text{row rank of} \\ A = \\text{column rank of} \\ A\n$$\n\nFrom the above inequality it follows that\n\n$$\nRank(A) \\leq min(m, n)\n$$\n\nThis means that if a matrix has, for example, 3 rows and 5 columns, its rank cannot be more than 3.\nThe rank of a matrix would be zero if and only if the matrix had no elements. If a matrix had even one element,\nits minimum rank would be one. When all of the vectors in a matrix are linearly independent, the matrix is said to be **full rank**.\n\nTo calculate the rank of a matrix, we have to compute the determinant. It turns out that the rank of a matrix $A$,\ndenoted by $Rank(A)$ is the size of the largest non-zero $m \\times m$ sub-matrix with non-zero determinant.\nTo simplify further, if the determinant of $4 \\times 4$ matrix $A$ is zero and any $3 \\times3$ sub-matrix of original\nmatrix $A$ has non-zero determinant then the rank of the original matrix $A$ is $3$.\nSo we can say that rank shows the [\"non-degenerateness\"](https://en.wikipedia.org/wiki/Degenerate_bilinear_form) of the matrix $A$.\n\nActually, there is no only one way to compute the rank. I will provide one more way in the advanced tutorial.\n\n::: {#f75ac83c .cell execution_count=8}\n``` {.python .cell-code}\nA = np.array([[1, 2, 3], [2, 4, 6], [1, -3, 5]])\n\nrank_A = np.linalg.matrix_rank(A)\n\nprint(\"Rank(A) = \", rank_A)\n\n\n# matrix B has full rank\nB = np.array([[2, 2, -1], [4, 0, 2], [0, 6, -3]])\n\nrank_B = np.linalg.matrix_rank(B)\n\nprint(\"Rank(B) = \", rank_B)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRank(A) =  2\nRank(B) =  3\n```\n:::\n:::\n\n\n### Power of a Matrix\n\nWe can rise a square matrix $A$ in any nonnegative power just like any number. This is defined as the product of\n$A$ by itself $n$ times. If matrix $A$ has inverse, then $A^{-n} = (A^{-1})^{n}$ or take inverse of $A$ and multiply by itself $n$ times.\n\nFor example, if\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 2 \\\\\n    3 & 4\n\\end{bmatrix}\n$$\n\nthen\n\n$$\nA^{2} =\nA A\n\\ =\n\\begin{bmatrix}\n    1 & 2 \\\\\n    3 & 4\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n    1 & 2 \\\\\n    3 & 4\n\\end{bmatrix}\n\\ =\n\\begin{bmatrix}\n    7 & 10 \\\\\n    15 & 22\n\\end{bmatrix}\n$$\n\n::: {#2b8273d2 .cell execution_count=9}\n``` {.python .cell-code}\nA = np.array([[1, 2], [3, 4]])\n\nA_square = np.linalg.matrix_power(A, 2)\nprint(A_square)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[ 7 10]\n [15 22]]\n```\n:::\n:::\n\n\n### Norm of a Matrix\n\nIn the previous post I talked about vector norms but did not mentioned matrix norm. There are three types of matrix norms:\n\n* Matrix norms induced by vector norms\n* Entrywise matrix norms\n* Schatten norms\n\nHere, I will introduce only the first two types of matrix norm and depict one example of each to give the general idea of matrix norms.\n\nInduced norms usually are denoted by: $$\\|A\\|_p$$\n\nIn the special cases of $p = 1, 2, \\infty$, the induced matrix norms can be computed by:\n\n$$\n\\|A\\|_1 = max_{1\\leq j \\leq m} \\sum_{i = 1}^{m}|a_{ij}|\n$$\n\nWhich is the maximum absolute column sum of the matrix $A$\n\n$$\n\\|A\\|_2 = \\|A\\|_F = \\sigma_{max}(A)\n$$\n\nWhere $\\|A\\|_F$ is Frobenius Norm, which will be discussed below and $\\sigma_{max}(A)$ is the spectral norm. The later will be discussed in the next post.\n\n$$\n\\|A\\|_{\\infty} = max_{1\\leq i \\leq m} \\sum_{j = 1}^{n}|a_{ij}|\n$$\n\nwhich is the maximum absolute row sum of the matrix $A$.\n\nTo clarify this farther, let consider the following example:\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6 \\\\\n    7 & 8 & 9\n\\end{bmatrix}\n$$\n\n$$\n\\|A\\|_1 = max(|1| + |4| + |7|; |2| + |5| + |8|; |3| + |6| + |9|) = max(12; 15; 18) = 18\n$$\n$$\n\\quad\n$$\n$$\n\\|A\\|_{\\infty} = max(|1| + |2| + |3|; |4| + |5| + |6|; |7| + |8| + |9|) = max(6; 15; 24) = 24\n$$\n\nImagine, we have a vector whose elements are matrices instead of scalars. Then norm defined here is entrywise matrix norm.\nThe general formula for entrywise matrix norm is:\n\n$$\n\\|A\\|_{p,q} = \\left(\\sum_{j=1}^{n}\\left(\\sum_{i=1}^{m}|a_{ij}^{p}\\right)^\\frac{q}{p}\\right)^\\frac{1}{q}\n$$\n\nwhere $p,q \\geq 1$\n\nWhen $p=q=2$ we have Frobenius Norm or Frobenius Inner Product:\n\n$$\n\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^{n}|a_{ij}|^2}\n$$\n\nand when $p=q=\\infty$, we have Max Norm:\n\n$$\n\\|A\\|_{max} = max_{ij}|a_{ij}|\n$$\n\nIf we have matrix $A$ such that:\n\n$$\nA =\n\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6 \\\\\n    7 & 8 & 9\n\\end{bmatrix}\n$$\n\nThen Frobenius Norm is:\n\n$$\n\\|A\\|_{F} = \\sqrt{(|1|^2 + |2|^2 + |3|^2 + |4|^2 + |5|^2 + |6|^2 + |7|^2 + |8|^2 + |9|^2)} =\n$$\n\n$$\n\\sqrt{1 + 4 + 9 + 16 + 25 + 36 + 49 + 64 + 81} = \\sqrt{285} \\approx 16.89\n$$\n\nFor two matrices $A$ and $B$ we have Frobenius Inner Product:\n\n$$\n\\langle A,B \\rangle_{F} = \\sum_{i,j}\\overline{A_{i,j}}B_{i,j} = tr \\left(\\overline{A^T}B \\right)\n$$\n\nWhere overline denotes the complex conjugate of a matrix.\n\nIf\n\n$$\nA =\n\\begin{bmatrix}\n    2 & 0 \\\\\n    1 & 1 \\\\\n\\end{bmatrix}\n$$\n\nand\n\n$$\nB =\n\\begin{bmatrix}\n    8 & -3 \\\\\n    4 & 1 \\\\\n\\end{bmatrix}\n$$\n\nthen\n\n$$\n\\langle A,B \\rangle_{F} = 2 \\cdot 8 + 0 \\cdot (-3) + 1 \\cdot 4 + 1 \\cdot 1 = 21\n$$\n\n::: {#da109d28 .cell execution_count=10}\n``` {.python .cell-code}\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nfrobenius_norm = np.linalg.norm(A, ord=\"fro\")\ncolumn_max_norm = np.linalg.norm(A, ord=1)\nrow_max_norm = np.linalg.norm(A, ord=np.inf)  # same as infinity norm\n\n# Frobenius Inner Product\nA = np.array([[2, 0], [1, 1]])\nB = np.array([[8, -3], [4, 1]])\n\n# numpy.vdot function flattens high dimensional arrays and takes dot product\nfrobenius_inner_product = np.vdot(A, B)\n\nprint(\"Frobenius Norm is: \", frobenius_norm)\nprint(\"Column Max Norm is: \", column_max_norm)\nprint(\"Row Max Norm is: \", row_max_norm)\nprint(\"Frobenius Inner Product is: \", frobenius_inner_product)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFrobenius Norm is:  16.881943016134134\nColumn Max Norm is:  18.0\nRow Max Norm is:  24.0\nFrobenius Inner Product is:  21\n```\n:::\n:::\n\n\n# Conclusion\n\nTo sum up both part of intermediate linear algebra, we've reviewed a lot of materials. Some of them seemed easy, while some of them at the first glance seemed complex, but I do hope a little more practice and reading this tutorial 2 times will help you to master all of these intuitions further. \n\n\n#### References\n* [Introduction To Linear Algebra](http://math.mit.edu/~gs/linearalgebra/)\n* [Linear Algebra Topics](https://en.wikipedia.org/wiki/List_of_linear_algebra_topics)\n* [Khan Academy - Linear Algebra](https://www.khanacademy.org/math/linear-algebra)\n\n",
    "supporting": [
      "linear_algebra_4_files"
    ],
    "filters": [],
    "includes": {}
  }
}